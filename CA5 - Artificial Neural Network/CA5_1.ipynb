{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> AI CA5 REPORT </h1>\n",
    "<h2>Atieh Armin - 810197648 </h2>\n",
    "<p>The goal of this computer assignment is to get acquainted with Neural Networks.</p>\n",
    "<h3>Preprocessing </h3>\n",
    "<p>First, the examples of each class of train data are given.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  0\n",
      "[  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  41. 188. 103.  54.\n",
      "  48.  43.  87. 168. 133.  16.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   0.   0.   0.  49. 136. 219. 216. 228. 236. 255.\n",
      " 255. 255. 255. 217. 215. 254. 231. 160.  45.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  14. 176. 222. 224. 212. 203. 198. 196. 200.\n",
      " 215. 204. 202. 201. 201. 201. 209. 218. 224. 164.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 188. 219. 200. 198. 202. 198. 199. 199. 201.\n",
      " 196. 198. 198. 200. 200. 200. 200. 201. 200. 225.  41.   0.   0.   0.\n",
      "   0.   0.   0.   0.  51. 219. 199. 203. 203. 212. 238. 248. 250. 245.\n",
      " 249. 246. 247. 252. 248. 235. 207. 203. 203. 222. 140.   0.   0.   0.\n",
      "   0.   0.   0.   0. 116. 226. 206. 204. 207. 204. 101.  75.  47.  73.\n",
      "  48.  50.  45.  51.  63. 113. 222. 202. 206. 220. 224.   0.   0.   0.\n",
      "   0.   0.   0.   0. 200. 222. 209. 203. 215. 200.   0.  70.  98.   0.\n",
      " 103.  59.  68.  71.  49.   0. 219. 206. 214. 210. 250.  38.   0.   0.\n",
      "   0.   0.   0.   0. 247. 218. 212. 210. 215. 214.   0. 254. 243. 139.\n",
      " 255. 174. 251. 255. 205.   0. 215. 217. 214. 208. 220.  95.   0.   0.\n",
      "   0.   0.   0.  45. 226. 214. 214. 215. 224. 205.   0.  42.  35.  60.\n",
      "  16.  17.  12.  13.  70.   0. 189. 216. 212. 206. 212. 156.   0.   0.\n",
      "   0.   0.   0. 164. 235. 214. 211. 220. 216. 201.  52.  71.  89.  94.\n",
      "  83.  78.  70.  76.  92.  87. 206. 207. 222. 213. 219. 208.   0.   0.\n",
      "   0.   0.   0. 106. 187. 223. 237. 248. 211. 198. 252. 250. 248. 245.\n",
      " 248. 252. 253. 250. 252. 239. 201. 212. 225. 215. 193. 113.   0.   0.\n",
      "   0.   0.   0.   0.   0.  17.  54. 159. 222. 193. 208. 192. 197. 200.\n",
      " 200. 200. 200. 201. 203. 195. 210. 165.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  47. 225. 192. 214. 203. 206. 204.\n",
      " 204. 205. 206. 204. 212. 197. 218. 107.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   1.   6.   0.  46. 212. 195. 212. 202. 206. 205.\n",
      " 204. 205. 206. 204. 212. 200. 218.  91.   0.   3.   1.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.  11. 197. 199. 205. 202. 205. 206.\n",
      " 204. 205. 207. 204. 205. 205. 218.  77.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   3.   0.   2. 191. 198. 201. 205. 206. 205.\n",
      " 205. 206. 209. 206. 199. 209. 219.  74.   0.   5.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   2.   0.   0. 188. 197. 200. 207. 207. 204.\n",
      " 207. 207. 210. 208. 198. 207. 221.  72.   0.   4.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   2.   0.   0. 215. 198. 203. 206. 208. 205.\n",
      " 207. 207. 210. 208. 200. 202. 222.  75.   0.   4.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 212. 198. 209. 206. 209. 206.\n",
      " 208. 207. 211. 206. 205. 198. 221.  80.   0.   3.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 204. 201. 205. 208. 207. 205.\n",
      " 211. 205. 210. 210. 209. 195. 221.  96.   0.   3.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 202. 201. 205. 209. 207. 205.\n",
      " 213. 206. 210. 209. 210. 194. 217. 105.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 204. 204. 205. 208. 207. 205.\n",
      " 215. 207. 210. 208. 211. 193. 213. 115.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 204. 207. 207. 208. 206. 206.\n",
      " 215. 210. 210. 207. 212. 195. 210. 118.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 198. 208. 208. 208. 204. 207.\n",
      " 212. 212. 210. 207. 211. 196. 207. 121.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 198. 210. 207. 208. 206. 209.\n",
      " 213. 212. 211. 207. 210. 197. 207. 124.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 172. 210. 203. 201. 199. 204.\n",
      " 207. 205. 204. 201. 205. 197. 206. 127.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 188. 221. 214. 234. 236. 238.\n",
      " 244. 244. 244. 240. 243. 214. 224. 162.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0. 139. 146. 130. 135. 135. 137.\n",
      " 125. 124. 125. 121. 119. 114. 130.  76.   0.   0.   0.   0.   0.   0.]\n",
      "Label =  1\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.  53. 146. 127. 115. 111.\n",
      " 130. 129. 100. 147. 169. 190.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 117. 190. 188. 221. 234.\n",
      " 254. 236. 221. 205. 186. 222.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 127. 156. 175. 193. 195.\n",
      " 195. 202. 203. 187. 168. 228.  32.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 165. 186. 198. 209. 219.\n",
      " 198. 205. 211. 201. 189. 233.  94.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 185. 199. 210. 225. 207.\n",
      " 201. 207. 221. 210. 208. 236. 111.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. 200. 175. 172. 215. 224.\n",
      " 216. 216. 223. 210. 198. 237. 152.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   7. 213. 156. 151. 171. 187.\n",
      " 215. 227. 212. 200. 178. 215. 177.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  25. 201. 136. 156. 178. 198.\n",
      " 213. 235. 168. 166. 163. 207. 178.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  42. 195. 134. 162. 171. 201.\n",
      "   1. 229. 198. 166. 154. 193. 173.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  50. 184. 134. 167. 184. 181.\n",
      "   0. 213. 190. 197. 179. 189. 179.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 175. 134. 169. 169. 211.\n",
      "   0. 196. 178. 153. 183. 196. 176.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  50. 173. 134. 167. 174. 223.\n",
      "   0. 161. 208. 140. 172. 198. 173.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 169. 125. 158. 187. 213.\n",
      "   0. 124. 219. 132. 149. 198. 176.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 168. 128. 150. 192. 197.\n",
      "   0.  82. 219. 152. 153. 177. 175.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  50. 174. 136. 144. 190. 185.\n",
      "   0.  29. 221. 155. 153. 184. 174.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  53. 175. 140. 161. 191. 143.\n",
      "   0.  13. 221. 154. 156. 184. 173.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  58. 184. 122. 166. 198. 115.\n",
      "   0.   0. 217. 158. 160. 180. 167.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  58. 204. 111. 172. 203.  79.\n",
      "   0.   0. 204. 164. 155. 188. 169.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 214. 138. 177. 209.  41.\n",
      "   0.   0. 186. 180. 152. 187. 168.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 214. 149. 177. 210.  23.\n",
      "   0.   0. 158. 199. 173. 192. 163.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 216. 159. 187. 204.   6.\n",
      "   0.   0. 136. 198. 189. 208. 165.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  55. 212. 161. 197. 191.   0.\n",
      "   0.   0. 118. 192. 185. 214. 161.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  63. 201. 162. 207. 171.   0.\n",
      "   0.   0.  86. 197. 184. 214. 156.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  68. 197. 168. 213. 155.   0.\n",
      "   0.   0.  64. 196. 183. 219. 154.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  73. 193. 168. 215. 146.   0.\n",
      "   1.   0.  56. 190. 180. 205. 146.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  73. 176. 168. 204. 137.   0.\n",
      "   3.   0.  37. 186. 179. 204. 138.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  94. 197. 178. 212. 129.   0.\n",
      "   5.   0.  32. 193. 185. 210. 150.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  49. 122. 126. 160.  65.   0.\n",
      "   3.   0.   8. 156. 173. 188. 107.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Label =  2\n",
      "[  0.   0.   0.   0.   1.   0.   0.   0.   0.  22.  88. 188. 172. 132.\n",
      " 125. 141. 199. 143.   9.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   0.   0.  20. 131. 199. 206. 196. 202. 242. 255.\n",
      " 255. 250. 222. 197. 206. 188. 126.  17.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   0.  35. 214. 191. 183. 178. 175. 168. 150. 162.\n",
      " 159. 152. 158. 179. 183. 189. 195. 185.  82.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 170. 190. 172. 177. 176. 171. 169. 162. 155.\n",
      " 148. 154. 169. 174. 175. 175. 177. 183. 188.  12.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  25. 194. 180. 178. 174. 184. 187. 189. 187. 184.\n",
      " 181. 189. 200. 197. 193. 190. 178. 175. 194.  90.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  42. 218. 191. 197. 208. 204. 211. 209. 210. 212.\n",
      " 211. 214. 215. 213. 214. 211. 211. 191. 200. 158.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  88. 221. 215. 217. 219. 211. 185. 150. 118. 107.\n",
      "  99.  88.  83.  90. 135. 212. 203. 207. 219. 169.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  27. 118. 162.  40.   0.   0.   0.  10.  19.\n",
      "  28.  39.  47.  36.   0.   0. 203. 230. 220. 203.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 138. 136.  71.  69.  54. 216. 217. 203. 184. 168.\n",
      " 163. 162. 163. 178. 221. 186.  38.  26.   7.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  67. 134. 154. 224. 129.  66.  81. 117. 129. 128.\n",
      " 132. 137. 131. 129.  86.  73. 157. 151. 134. 216.  18.   0.   0.   0.\n",
      "   0.   0.   0.   0. 203. 198. 172. 183. 206. 255. 255. 250. 243. 240.\n",
      " 239. 235. 238. 244. 255. 238. 184. 160.  86.  98.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0. 122. 188. 224. 151. 105. 127.  97. 100. 105. 114.\n",
      " 117. 117. 113. 103.  98. 111. 142. 254. 191. 255.  49.   0.   0.   0.\n",
      "   0.   0.   0.   0. 163. 179. 200.  95. 154. 198. 197. 200. 200. 198.\n",
      " 197. 198. 199. 202. 200. 176.  86. 206. 157. 162.  10.   0.   0.   0.\n",
      "   0.   0.   0.   0. 197. 201. 229.  71. 144. 194. 181. 183. 179. 182.\n",
      " 180. 179. 180. 190. 185. 197.  76. 219. 185. 201.  34.   0.   0.   0.\n",
      "   0.   0.   0.   0. 199. 193. 226.  58. 154. 192. 184. 187. 184. 186.\n",
      " 184. 185. 183. 192. 191. 200.  56. 219. 203. 207.  60.   0.   0.   0.\n",
      "   0.   0.   0.   0. 201. 194. 224.  41. 163. 190. 186. 186. 184. 185.\n",
      " 183. 185. 178. 190. 194. 202.  33. 211. 200. 206.  73.   0.   0.   0.\n",
      "   0.   0.   0.   0. 201. 197. 222.  17. 172. 190. 186. 187. 182. 186.\n",
      " 185. 187. 180. 187. 193. 202.  26. 212. 202. 203.  76.   0.   0.   0.\n",
      "   0.   0.   0.   0. 200. 197. 223.   0. 177. 189. 184. 185. 178. 184.\n",
      " 183. 184. 180. 183. 189. 203.  35. 196. 203. 203.  84.   0.   0.   0.\n",
      "   0.   0.   0.   0. 200. 197. 223.   0. 185. 187. 185. 187. 180. 184.\n",
      " 182. 183. 178. 182. 183. 205.  44. 159. 207. 201.  85.   0.   0.   0.\n",
      "   0.   0.   0.   0. 187. 198. 225.   0. 194. 188. 184. 185. 180. 183.\n",
      " 183. 184. 181. 181. 177. 206.  46. 129. 211. 200.  88.   0.   0.   0.\n",
      "   0.   0.   0.   6. 186. 200. 211.   0. 199. 189. 184. 184. 185. 182.\n",
      " 183. 184. 185. 182. 175. 205.  50.  97. 216. 197.  93.   0.   0.   0.\n",
      "   0.   0.   0.   5. 185. 204. 184.   0. 202. 188. 182. 182. 183. 183.\n",
      " 184. 182. 180. 182. 174. 202.  63.  59. 220. 196.  94.   0.   0.   0.\n",
      "   0.   0.   0.   5. 184. 206. 157.   0. 204. 187. 187. 189. 192. 190.\n",
      " 190. 191. 190. 187. 183. 202.  78.  35. 222. 197.  95.   0.   0.   0.\n",
      "   0.   0.   0.   5. 183. 208. 127.   0. 197. 166. 153. 149. 149. 146.\n",
      " 148. 149. 150. 151. 158. 191.  90.   8. 223. 195.  99.   0.   0.   0.\n",
      "   0.   0.   0.   6. 184. 208. 114.   0. 204. 173. 161. 180. 176. 172.\n",
      " 173. 173. 174. 176. 162. 202. 115.   0. 229. 199. 105.   0.   0.   0.\n",
      "   0.   0.   0.   9. 178. 204. 115.   0. 121. 135. 114. 117. 114. 114.\n",
      " 117. 118. 119. 117. 113. 147.  63.   0. 225. 196. 107.   0.   0.   0.\n",
      "   0.   0.   0.  18. 180. 206. 131.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 224. 197. 123.   0.   0.   0.\n",
      "   0.   0.   0.   0. 141. 151.  76.   0.   1.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 133. 167.  73.   0.   0.   0.]\n",
      "Label =  3\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.  33.  96. 175. 156.  64.  14.\n",
      "  54. 137. 204. 194. 102.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  73. 186. 177. 183. 175. 188. 232. 255.\n",
      " 223. 219. 194. 179. 186. 213. 146.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  35. 163. 140. 150. 152. 150. 146. 175. 175.\n",
      " 173. 171. 156. 152. 148. 129. 156. 140.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 150. 142. 140. 152. 160. 156. 146. 142. 127.\n",
      " 135. 133. 140. 140. 137. 133. 125. 169.  75.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  54. 167. 146. 129. 142. 137. 137. 131. 148.\n",
      " 148. 133. 131. 131. 131. 125. 140. 140.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 110. 188. 133. 146. 152. 133. 125. 127.\n",
      " 119. 129. 133. 119. 140. 131. 150.  14.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 221. 158. 137. 135. 123. 110. 110.\n",
      " 114. 108. 112. 117. 127. 142.  77.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   4.   0.  25. 158. 137. 125. 119. 119. 110.\n",
      " 117. 117. 110. 119. 127. 144.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 123. 156. 129. 112. 110. 102.\n",
      " 112. 100. 121. 117. 129. 114.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 125. 169. 127. 119. 106. 108.\n",
      " 104.  94. 121. 114. 129.  91.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  98. 171. 129. 112. 104. 114.\n",
      " 106. 102. 112. 104. 133.  64.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  66. 173. 135. 129.  98. 100.\n",
      " 119. 102. 108.  98. 135.  60.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  56. 171. 135. 127. 100. 108.\n",
      " 117.  85. 106. 110. 135.  66.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  52. 150. 129. 110. 100.  91.\n",
      " 102.  94.  83. 104. 123.  66.   0.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.   0.  66. 167. 140. 148. 148. 127.\n",
      " 137. 152. 146. 146. 148.  96.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  45. 123.  94. 104.  96. 119.\n",
      " 121. 106.  98. 112.  87. 114.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0. 106.  89.  58.  50.  37.  50.\n",
      "  66.  56.  50.  75.  75. 137.  22.   0.   2.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   2.   0.  29. 148. 114. 106. 125.  89. 100.\n",
      " 133. 117. 131. 131. 131. 125. 112.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 100. 106. 114.  91. 137.  62. 102.\n",
      " 131.  89. 135. 112. 131. 108. 135.  37.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 146. 100. 108.  98. 144.  62. 106.\n",
      " 131.  87. 133. 104. 160. 117. 121.  68.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  33. 121. 108.  96. 100. 140.  71. 106.\n",
      " 127.  85. 140. 104. 150. 140. 114.  89.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  62. 119. 112. 102. 110. 137.  75. 106.\n",
      " 144.  81. 144. 108. 117. 154. 117. 104.  18.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  66. 121. 102. 112. 117. 131.  73. 104.\n",
      " 156.  77. 137. 135.  83. 179. 129. 121.  35.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 127.  81. 125. 133. 119.  79. 100.\n",
      " 169.  83. 129. 175.  60. 163. 135. 146.  39.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 106. 129.  62. 140. 144. 108.  85.  83.\n",
      " 158.  85. 129. 175.  48. 146. 133. 135.  64.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 117. 119.  79. 140. 152. 102.  89. 110.\n",
      " 137.  96. 150. 196.  83. 144. 135. 133.  77.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 154. 121.  87. 140. 154. 112.  94.  52.\n",
      " 142. 100.  83. 152.  85. 160. 133. 100.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   4.   0.   2.   0.  35.   4.  33.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Label =  4\n",
      "[  0.   0.   0.   0.   0.   0.   0.   2.   0.   0.  12.  55.  98.  52.\n",
      "  45.  70.  47.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  39.  52.  93. 144.  83.\n",
      "  66.  86.  78.  48.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  35.  67.  36. 118. 151.  60.\n",
      "  28.  63.  44.  60.  52.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  51.  43.  29.  90. 211. 232.\n",
      " 157.  90.  22.  21.  53.   9.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   2.  36.  63.  99.  70.  63. 246. 241.\n",
      " 164. 116.  80. 110. 145. 117.  28.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  36.  66.  56.  63. 109.  55. 223. 255.\n",
      " 225. 110. 134. 105.  79.  76.  87.  49.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  52.  43.  59.  62.  39.  25.  44. 229.\n",
      " 228.  43.  40.  43.  62.  51.  56.  74.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   9.  58.  48.  49.  58.  60.  47.  16. 234.\n",
      " 180.  17.  59.  55.  64.  53.  60.  75.  40.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  29.  59.  40.  48.  40.  47.  56.  32.  78.\n",
      "  60.  41.  60.  49.  59.  49.  78.  72.  63.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  37.  68.  53.  37.  47.  45.  49.  22. 156.\n",
      "  93.  28.  56.  53.  62.  58. 103.  55.  79.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  52.  56.  66.  41.  41.  48.  49.  31.  89.\n",
      "  60.  37.  48.  56.  56.  63.  93.  49.  87.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  10.  66.  60.  99.  55.  39.  47.  47.  37.  76.\n",
      "  62.  39.  51.  60.  58.  72. 113.  47.  98.  20.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   9.  63.  71. 113.  48.  39.  47.  51.  35.  85.\n",
      "  67.  39.  63.  64.  59. 110. 140.  52.  87.  43.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  14.  53.  68. 106.  29.  48.  47.  55.  37.  74.\n",
      "  58.  45.  58.  62.  59. 121. 120.  37.  95.  52.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  24.  56.  67. 124.  36.  47.  48.  51.  39.  75.\n",
      "  76.  47.  51.  68.  71. 117. 140.  60.  76.  60.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  43.  62.  70. 114.  36.  43.  49.  49.  33.  75.\n",
      "  78.  39.  53.  66.  74.  98. 126.  62.  68.  89.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  49.  68. 107. 116.  12.  56.  44.  52.  33.  74.\n",
      "  75.  33.  66.  49. 101.  86. 103.  85.  86. 109.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  44.  71. 114.  97.  18.  66.  44.  52.  44.  67.\n",
      "  79.  47.  59.  33. 133.  91.  49. 121.  76. 110.  40.   0.   0.   0.\n",
      "   0.   0.   0.   0.  53.  68. 121.  37.  16.  55.  47.  52.  40.  66.\n",
      "  83.  47.  49.  49.  97.  91.  29. 102.  70. 109.  60.   0.   0.   0.\n",
      "   0.   0.   0.   0.  47.  56. 113.  32.  18.  55.  47.  59.  37.  60.\n",
      "  91.  33.  60.  62.  63.  90.   8. 114.  76.  80.  49.   0.   0.   0.\n",
      "   0.   0.   0.   0.  48.  59.  99.  20.  29.  52.  49.  55.  41.  64.\n",
      "  89.  35.  64.  48.  55. 111.  14.  59.  70.  67.  36.   0.   0.   0.\n",
      "   0.   0.   0.   0.  45.  63. 106.   0.  52.  52.  49.  48.  43.  58.\n",
      "  90.  49.  56.  59.  59.  99.  43.  21.  83.  76.  52.   0.   0.   0.\n",
      "   0.   0.   0.   0.  45.  63.  97.   0.  43.  48.  52.  48.  41.  55.\n",
      "  94.  43.  58.  70.  55.  85.  49.   5.  86.  75.  45.   0.   0.   0.\n",
      "   0.   0.   0.   0.  45.  70.  67.  14.  86.  41.  49.  51.  45.  58.\n",
      "  89.  36.  67.  63.  53.  80.  56.   1.  86.  71.  48.   0.   0.   0.\n",
      "   0.   0.   0.   0.  58.  99.  51.  45. 118.  39.  52.  48.  47.  55.\n",
      "  63.  55.  64.  53.  67.  70.  78.   0.  82.  91.  68.   0.   0.   0.\n",
      "   0.   0.   0.   0.  14.  25.  10.  29.  39.  49.  53.  44.  45.  48.\n",
      "  49.  64.  51.  62.  64.  58.  90.   6.   0.  13.   8.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  60.  60.  53.  53.  55.  55.  53.\n",
      "  66.  63.  62.  70.  70.  76.  93.  36.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   4.  53.  45.  53.  44.  43.  39.  43.\n",
      "  45.  41.  62.  49.  60.  56.  67.  22.   0.   2.   0.   0.   0.   0.]\n",
      "Label =  5\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   3.\n",
      "   1.   0.   0.   1.   1.   0.   0.   0.   0.  58.   0.  39.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   3.\n",
      "   0.   0.   0.   0.   0.   0.   0.  64. 109. 146. 192. 193.   7.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.  94.  38.  99. 209. 183. 229. 192. 142.  48.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.\n",
      "  41.  45. 158. 146. 164. 114.  51.   1.  53. 105.  42.  36.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  68.\n",
      "  44.  30.  59. 172. 146.   0.  22.   0.  13. 103. 111. 103.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   1.   0.  22.  61.\n",
      "  88. 152. 255.  71.   0.   0.   0.   0.  35.  85. 112. 201.  44.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  13.  62.\n",
      " 154.  62.   0.   0.   0.   0.   0.   0.  54.  99.  61. 106.  51.  19.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   9.   1.   0.   0.   1.   0.  79.  82.  47.  33.  58.  50.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.\n",
      "   1.   3.   9.   3.   0.   0.   1.   0. 100.  88.  48.  35.  70.  54.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   3.   0.   1.   0.   0. 111. 195. 119.  29.  58.  45.\n",
      "   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   3.   3.   0.   0.  91. 146. 171.  16.  93.  35.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  48.  45.   3.  79.  87.  99.   6.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   3.   0.   0. 119. 137.  33.  96.  77.  13.  45.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  32. 160. 164. 142. 116.  79.  82.  39.  39.   0.\n",
      "   0.   0.   0.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   3.\n",
      "   4.  10.   0.  41. 180. 142. 171.   1.   0.   0.  48.  73.  16.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.\n",
      "   3.   0.  27. 155. 114. 169.   0.   0.   0.   0.  47.  76.   6.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0. 155. 129. 160.   0.   0.   0.   0.   0.  45.  96.   0.   0.\n",
      "   0.   0.   0.   0.   1.   0.  16.  39.  64.   0.   0.   0.   0.   0.\n",
      "   0. 129. 151. 175.   0.   0.   0.   4.   4.   0.  48. 116.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  58.  87.  73.  10.   0.   0.   0.   0.\n",
      "  27. 187. 195.   0.   0.   0.   0.   3.   1.   0.  47. 146.   0.   0.\n",
      "   1.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 181. 225.  45.   0.   0.   0.   0.   0.   1.   0.  45. 186.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1. 183. 210.  90.   0.   0.   0. 126.\n",
      " 253. 142.   0.   0.   0.   0.   0.   0.   1.   0.  48. 203.   0.   0.\n",
      "  64.  58.  45.  27.  16.   9.   1. 175. 245. 204.  22.   0.  70. 236.\n",
      " 190.   6.   0.   0.   0.   0.   0.   0.   0.   0.  50. 196.   0.   0.\n",
      "  96. 128. 149. 163. 158. 140. 138. 146. 154. 108.  90. 148. 193. 177.\n",
      "  36.   0.   7.   0.   0.   0.   0.   0.   0.   0.  41. 125.   0.   0.\n",
      "   0.   0.   0.   0.  19.  47.  65.  93.  94. 125. 166. 180. 119.  29.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  32. 238.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 131.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Label =  6\n",
      "[  0.   0.   0.   2.   0.   2.   0.   0.   6.  36.  79.  24.   0.   0.\n",
      "   0.   0.   0.  31.  73.   1.   0.   0.   0.   2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   1.   2.   0.   0. 153. 160. 153. 176. 189. 188. 194.\n",
      " 145. 154. 149. 192. 179. 145. 161.  83.   0.   0.   2.   0.   0.   0.\n",
      "   0.   0.   0.   2.   0.   0. 135. 170. 144. 150. 147. 162. 187. 106.\n",
      "   1. 200. 177. 166. 146. 149. 151. 169. 113.   0.   3.   0.   0.   0.\n",
      "   0.   0.   0.   4.   0.  34. 179. 149. 151. 150. 145. 135. 169. 136.\n",
      "  86. 190. 156. 143. 146. 148. 146. 143. 157.   3.   0.   3.   0.   0.\n",
      "   0.   0.   0.   0.   0. 101. 177. 160. 152. 155. 150. 148. 144. 156.\n",
      " 163. 141. 154. 152. 150. 145. 147. 144. 163.  64.   0.   4.   0.   0.\n",
      "   0.   0.   0.   0.   0. 143. 178. 171. 154. 156. 149. 145. 149. 149.\n",
      " 145. 148. 147. 152. 148. 137. 152. 155. 162. 108.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 178. 174. 176. 163. 155. 144. 141. 146. 149.\n",
      " 140. 146. 143. 143. 139. 144. 150. 161. 163. 129.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   5. 166. 180. 174. 190. 161. 147. 146. 149. 149.\n",
      " 147. 147. 149. 147. 143. 144. 157. 179. 150. 163.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  30. 176. 178. 186. 208. 151. 149. 151. 154. 152.\n",
      " 152. 151. 152. 149. 141. 134. 194. 183. 155. 179.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  80. 181. 182. 196. 212. 147. 152. 150. 152. 151.\n",
      " 151. 151. 151. 147. 142. 131. 190. 198. 159. 160.  32.   0.   0.   0.\n",
      "   0.   0.   0.   0. 103. 182. 175. 206. 197. 152. 148. 150. 153. 154.\n",
      " 153. 150. 149. 142. 143. 136. 183. 224. 160. 161.  80.   0.   0.   0.\n",
      "   0.   0.   0.   0. 138. 187. 174. 225. 187. 150. 152. 152. 155. 154.\n",
      " 156. 154. 154. 147. 150. 131. 186. 227. 159. 162. 119.   0.   0.   0.\n",
      "   0.   0.   0.   0. 164. 195. 171. 235. 180. 154. 153. 153. 157. 157.\n",
      " 158. 152. 152. 147. 143. 137. 169. 232. 161. 173. 144.   0.   0.   0.\n",
      "   0.   0.   0.   0. 182. 200. 171. 231. 170. 154. 155. 157. 159. 159.\n",
      " 160. 157. 155. 144. 149. 142. 157. 232. 166. 187. 170.   0.   0.   0.\n",
      "   0.   0.   0.   0. 191. 201. 180. 251. 159. 157. 157. 157. 157. 159.\n",
      " 163. 152. 152. 147. 148. 148. 148. 226. 174. 193. 172.   0.   0.   0.\n",
      "   0.   0.   0.   7. 191. 209. 200. 203. 143. 166. 159. 157. 160. 162.\n",
      " 158. 156. 156. 143. 147. 154. 131. 215. 194. 195. 169.   5.   0.   0.\n",
      "   0.   0.   0.  24. 191. 212. 213. 212. 148. 166. 156. 155. 158. 161.\n",
      " 158. 156. 153. 145. 153. 148. 142. 204. 232. 184. 175.  27.   0.   0.\n",
      "   0.   0.   0.  40. 198. 213. 224. 193. 155. 162. 159. 157. 157. 164.\n",
      " 160. 160. 154. 145. 152. 154. 140. 161. 234. 178. 178.  38.   0.   0.\n",
      "   0.   0.   0.  46. 193. 224. 231. 122. 168. 163. 161. 159. 163. 171.\n",
      " 165. 169. 164. 152. 160. 155. 147. 124. 246. 190. 184.  49.   0.   0.\n",
      "   0.   0.   0.  42. 193. 225. 227. 115. 172. 150. 152. 150. 154. 152.\n",
      " 149. 156. 163. 152. 140. 139. 168.  87. 231. 195. 178.  63.   0.   0.\n",
      "   0.   0.   0.  52. 188. 217. 224. 107. 178. 174. 156. 165. 184. 162.\n",
      " 180. 174. 161. 171. 182. 166. 180.  86. 255. 186. 170.  72.   0.   0.\n",
      "   0.   0.   0.  58. 207. 232. 229. 120. 177. 181. 152. 160. 189. 183.\n",
      " 223. 167. 139. 156. 173. 179. 178.  62. 230. 146. 183.  78.   0.   0.\n",
      "   0.   0.   0.  70. 219. 232. 234. 175. 156. 185. 146. 164. 186. 186.\n",
      " 203. 155. 151. 160. 155. 198. 182. 131. 237. 164. 176. 101.   0.   0.\n",
      "   0.   0.   0.  91. 183. 198. 212. 151. 159. 178. 155. 159. 187. 195.\n",
      " 191. 152. 156. 156. 140. 210. 191. 137. 226. 203. 199. 100.   0.   0.\n",
      "   0.   0.   0.  98. 189. 192. 219. 150. 149. 166. 147. 148. 187. 211.\n",
      " 178. 152. 157. 148. 143. 188. 187. 125. 213. 200. 192.  96.   0.   0.\n",
      "   0.   0.   0.  87. 203. 171. 207. 171. 183. 172. 168. 165. 176. 199.\n",
      " 185. 161. 161. 161. 170. 187. 186. 155. 209. 195. 175.  63.   0.   0.\n",
      "   0.   0.   0.  44. 193. 217.  84.  80.  99.  79.  88. 125. 203. 171.\n",
      " 169. 199. 181. 186. 116. 118. 133. 114. 170. 221. 179.   4.   0.   0.\n",
      "   0.   0.   0.   0.  74. 133.   6.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  15. 160. 100.   0.   0.   0.]\n",
      "Label =  7\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   0.   3.   1.\n",
      "   0.   4.   0.   0.   0.   2.   0.   0.   0.   0.   5.   1.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   0.\n",
      "   0.   0.   0.   0. 106. 229.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      "   0.  90. 138. 223. 214. 209. 167.   0.   0.   0.   6. 124.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  37. 122.\n",
      " 179. 249. 214. 195. 181. 213. 241.   0.   0.   0.  94. 179.   0.   0.\n",
      "   0.   0.   0.   2.   0.   6.   0.   0.   0.   0.  16. 149. 236. 226.\n",
      " 201. 195. 200. 204. 155. 209. 116.   0.  22. 109. 251.  35.  51.   0.\n",
      "   0.   0.   1.   3.   0.   0.   0.   0.  67. 150. 240. 221. 194. 190.\n",
      " 204. 214. 205. 195. 207. 185. 206. 233. 224. 179.   2.  10.  22.   0.\n",
      "   0.   0.   0.   0.   0.   0. 110. 214. 237. 209. 196. 192. 215. 215.\n",
      " 213. 213. 207. 193. 186. 199. 206. 175.   0.   0. 124. 230. 200.  36.\n",
      "   0.  50. 119. 158. 166. 192. 204. 198. 187. 202. 203. 211. 214. 204.\n",
      " 209. 210. 204. 197. 191. 190. 191. 229. 230. 242. 214. 193. 203. 137.\n",
      " 108. 190. 199. 200. 194. 199. 194. 195. 199. 200. 189. 187. 191. 189.\n",
      " 197. 198. 205. 200. 200. 208. 213. 215. 212. 213. 209. 202. 216. 137.\n",
      "  15.  55. 114. 157. 188. 207. 216. 220. 217. 219. 221. 242. 240. 243.\n",
      " 249. 253. 255. 255. 243. 232. 226. 222. 221. 213. 215. 198. 209.  62.\n",
      "  16.  11.   0.   0.   7.  40.  76. 108. 134. 142. 143. 145. 143. 123.\n",
      " 111.  92.  76.  61.  45.  35.  25.  25.  31.  32.  32.  12.   1.   0.\n",
      "   0.  11.  25.  26.  26.  22.  12.  20.  15.  15.  18.  17.  19.  27.\n",
      "  30.  36.  41.  49.  57.  66.  79.  84.  79.  83.  93.  80.  75.  45.\n",
      "   0.   0.   0.   0.   0.   9.  14.  17.  27.  34.  39.  39.  42.  44.\n",
      "  41.  41.  43.  48.  43.  30.  31.  35.  40.  37.  40.  37.  26.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Label =  8\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   3.\n",
      "   1.   0.   1.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.  45.  40.  52.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  10.  96. 174. 128. 126. 114.  84. 100. 114.  77.  98.  77.  77.  93.\n",
      "  86.  84.  87. 107.  91.  94.  87.  87.  86.  91.  96. 103. 123.  26.\n",
      "  87. 144.  42. 103. 175. 167.  66. 117. 112. 133. 114. 121. 140. 131.\n",
      " 110. 149. 131. 110. 137. 128. 112. 105. 167. 186. 138.  98. 135.  63.\n",
      "  61. 140.  94. 156. 160. 145. 128.  65.  91. 205. 133. 165. 163.  75.\n",
      "  98. 160. 168. 140. 181. 124.  93. 131. 184. 181. 124. 119. 196.  38.\n",
      " 100. 168. 170. 126. 161. 177. 191.  63. 116. 170. 153. 154. 123.  75.\n",
      "  91. 131. 172. 168. 191. 124.  70. 170. 161. 117. 153. 205. 219.  47.\n",
      "  82. 189. 165. 161. 163. 198. 175.  98. 196. 144. 172. 126. 189. 156.\n",
      " 112. 184. 126. 189. 175. 174. 121. 172. 193. 182. 191. 189. 207.  52.\n",
      "  93. 156.  96. 168. 177. 158. 144. 121.  84. 149. 193. 193. 133.  73.\n",
      " 100. 110. 156. 230. 142.  70. 102. 126. 182. 200. 200. 158. 149.  29.\n",
      " 116. 138. 144. 182. 177. 172. 181. 191.  54. 145. 232.  91.  82. 165.\n",
      " 193.  96.  93. 221. 103.  79. 186. 202. 165. 189. 216. 167. 116.  42.\n",
      "  65. 145. 109. 119. 182. 198.  87. 110. 172. 165.  93.  68. 179. 198.\n",
      " 193. 153.  75. 112. 167. 191. 144. 105. 181. 219. 175. 172. 163.  59.\n",
      "  54. 218. 175.  86. 138. 156.  58. 177. 191. 221. 110.  58.  86. 168.\n",
      " 170. 103. 109. 119. 184. 189. 163.  56. 123. 198. 102. 198. 207.  61.\n",
      "  93. 168. 165. 128.  77.  82. 117. 131. 117. 158.  80. 149. 188. 112.\n",
      " 123. 163. 158. 110. 175. 163. 153. 131.  93.  86. 124. 202. 205.  89.\n",
      "  56. 177. 153.  89. 170. 128.  87. 211. 154. 182. 154. 175. 218. 124.\n",
      " 116. 253. 175. 133. 204. 191. 216. 138. 100. 174. 119. 151. 230.  51.\n",
      "  61. 116. 123. 154. 221. 144.  79. 177. 193. 193. 153. 109. 188. 145.\n",
      " 138. 209. 121. 130. 212. 211. 219. 109. 137. 255. 195. 114. 153.  72.\n",
      "  86. 102. 114. 138. 177. 130. 172. 200. 181. 172. 212. 149. 133.  96.\n",
      " 105. 100. 151. 170. 163. 184. 216. 175. 102. 204. 211. 116. 124.  73.\n",
      "  72. 114. 138.  86. 112. 147. 147. 140. 172. 165. 147. 153.  94. 112.\n",
      "  94. 117. 156. 151. 182. 165. 161. 177. 161. 165.  91. 130. 149.  49.\n",
      "  70. 121. 195. 175. 177. 193. 112.  80. 198. 154. 102. 109. 195. 189.\n",
      " 170. 181. 110.  58. 177. 209. 107.  61. 181. 207. 179. 207. 170.  63.\n",
      "  47. 112. 154. 161. 177. 119.  49.  98. 142. 107. 112. 119. 163. 186.\n",
      " 181. 188. 131. 102. 133. 158. 131.  94. 147. 184. 193. 205. 158.  43.\n",
      "  86. 200. 174. 161. 156. 209. 154. 109. 175. 170. 100. 161. 182. 174.\n",
      " 174. 198. 167. 112. 177. 165. 112. 142. 193. 179. 195. 202. 195. 100.\n",
      "  73. 130. 138. 182. 175. 154. 147. 119. 188. 184. 151. 145. 172. 172.\n",
      " 160. 131. 135. 137. 177. 188. 144. 147. 163. 181. 188. 163. 131.  61.\n",
      "  87. 109. 114. 205. 156. 100.  80. 140. 174. 184. 168.  87. 138. 168.\n",
      " 158. 105.  91. 121. 170. 182. 128. 140. 124. 109. 181.  96. 102.  93.\n",
      "  45.  98.  94. 121. 124. 142. 117. 116.  94. 170. 147. 110. 124. 123.\n",
      " 105. 110. 100.  94.  96. 119. 116. 112. 140. 102. 140. 123. 156.  70.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "Label =  9\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.  13.  73.   0.   0.   1.   4.   0.   0.   0.   0.   1.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   0.\n",
      "  36. 136. 127.  62.  54.   0.   0.   0.   1.   3.   4.   0.   0.   3.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.\n",
      " 102. 204. 176. 134. 144. 123.  23.   0.   0.   0.   0.  12.  10.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 155. 236. 207. 178. 107. 156. 161. 109.  64.  23.  77. 130.  72.  15.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  69.\n",
      " 207. 223. 218. 216. 216. 163. 127. 121. 122. 146. 141.  88. 172.  66.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   1.   1.   0. 200.\n",
      " 232. 232. 233. 229. 223. 223. 215. 213. 164. 127. 123. 196. 229.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 183.\n",
      " 225. 216. 223. 228. 235. 227. 224. 222. 224. 221. 223. 245. 173.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 193.\n",
      " 228. 218. 213. 198. 180. 212. 210. 211. 213. 223. 220. 243. 202.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   3.   0.  12. 219.\n",
      " 220. 212. 218. 192. 169. 227. 208. 218. 224. 212. 226. 197. 209.  52.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.  99. 244.\n",
      " 222. 220. 218. 203. 198. 221. 215. 213. 222. 220. 245. 119. 167.  56.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   4.   0.   0.  55. 236.\n",
      " 228. 230. 228. 240. 232. 213. 218. 223. 234. 217. 217. 209.  92.   0.\n",
      "   0.   0.   1.   4.   6.   7.   2.   0.   0.   0.   0.   0. 237. 226.\n",
      " 217. 223. 222. 219. 222. 221. 216. 223. 229. 215. 218. 255.  77.   0.\n",
      "   0.   3.   0.   0.   0.   0.   0.   0.   0.  62. 145. 204. 228. 207.\n",
      " 213. 221. 218. 208. 211. 218. 224. 223. 219. 215. 224. 244. 159.   0.\n",
      "   0.   0.   0.   0.  18.  44.  82. 107. 189. 228. 220. 222. 217. 226.\n",
      " 200. 205. 211. 230. 224. 234. 176. 188. 250. 248. 233. 238. 215.   0.\n",
      "   0.  57. 187. 208. 224. 221. 224. 208. 204. 214. 208. 209. 200. 159.\n",
      " 245. 193. 206. 223. 255. 255. 221. 234. 221. 211. 220. 232. 246.   0.\n",
      "   3. 202. 228. 224. 221. 211. 211. 214. 205. 205. 205. 220. 240.  80.\n",
      " 150. 255. 229. 221. 188. 154. 191. 210. 204. 209. 222. 228. 225.   0.\n",
      "  98. 233. 198. 210. 222. 229. 229. 234. 249. 220. 194. 215. 217. 241.\n",
      "  65.  73. 106. 117. 168. 219. 221. 215. 217. 223. 223. 224. 229.  29.\n",
      "  75. 204. 212. 204. 193. 205. 211. 225. 216. 185. 197. 206. 198. 213.\n",
      " 240. 195. 227. 245. 239. 223. 218. 212. 209. 222. 220. 221. 230.  67.\n",
      "  48. 203. 183. 194. 213. 197. 185. 190. 194. 192. 202. 214. 219. 221.\n",
      " 220. 236. 225. 216. 199. 206. 186. 181. 177. 172. 181. 205. 206. 115.\n",
      "   0. 122. 219. 193. 179. 171. 183. 196. 204. 210. 213. 207. 211. 210.\n",
      " 200. 196. 194. 191. 195. 191. 198. 192. 176. 156. 167. 177. 210.  92.\n",
      "   0.   0.  74. 189. 212. 191. 175. 172. 175. 181. 185. 188. 189. 188.\n",
      " 193. 198. 204. 209. 210. 210. 211. 188. 188. 194. 192. 216. 170.   0.\n",
      "   2.   0.   0.   0.  66. 200. 222. 237. 239. 242. 246. 243. 244. 221.\n",
      " 220. 193. 191. 179. 182. 182. 181. 176. 166. 168.  99.  58.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  40.  61.  44.  72.  41.  35.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_CLASSES = 10\n",
    "\n",
    "\n",
    "trainData = np.genfromtxt(\"trainData.csv\", delimiter = ',')\n",
    "trainLabels = np.genfromtxt(\"trainLabels.csv\", delimiter = ',')\n",
    "\n",
    "for i in range(N_CLASSES):\n",
    "    for j in range(len(trainLabels)):\n",
    "        if(trainLabels[j] == i):\n",
    "            print('Label = ',i)\n",
    "            print(trainData[j])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next step is to show the class distributions among train data and test data by bar charts. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAV7klEQVR4nO3dfdBedX3n8fdHAiK2JSBZShNoaI1l0SkPvQsoXacVy1MZsbvVxVpJGWYyzrAt2s5UcLpSUUc76/rUFnaygkTrSinqkqWMmOVBdF2QRJ5BlhSakpSHaACpVC3y3T+u360XIcm5ktznuu7kfr9mrrnO+Z3fOed7QSafnKffSVUhSdK2vGjSBUiSZj/DQpLUybCQJHUyLCRJnQwLSVKneZMuoA8HHHBALV68eNJlSNIuZc2aNd+uqgVbWrZbhsXixYtZvXr1pMuQpF1KknVbW+ZpKElSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUqdewSDI/yZVJvpXkviSvTrJ/klVJHmjf+7W+SfKJJGuT3Jnk6KHtLG39H0iytM+aJUkv1PeRxceBL1XVYcARwH3AecB1VbUEuK7NA5wCLGmfZcDFAEn2By4AjgWOAS6YDhhJ0nj0FhZJ9gVeC1wCUFU/rKongdOBFa3bCuCNbfp04NM1cDMwP8lBwEnAqqraVFVPAKuAk/uqW5L0Qn0+wX0osBH4VJIjgDXAucCBVfVI6/MocGCbXgg8PLT++ta2tfbnSbKMwREJhxxyyE4V/t68d6fW73JBXTAn972t/btv9+2++933zurzNNQ84Gjg4qo6CvgePznlBEANXtM3I6/qq6rlVTVVVVMLFmxxaBNJ0g7qMyzWA+ur6pY2fyWD8HisnV6ifT/elm8ADh5af1Fr21q7JGlMeguLqnoUeDjJL7WmE4B7gZXA9B1NS4Gr2vRK4Mx2V9RxwFPtdNW1wIlJ9msXtk9sbZKkMel71Nk/AD6bZC/gQeAsBgF1RZKzgXXAm1vfa4BTgbXAM60vVbUpyfuAW1u/C6tqU891S5KG9BoWVXU7MLWFRSdsoW8B52xlO5cCl85ocZKkkfkEtySpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpU69hkeQfktyV5PYkq1vb/klWJXmgfe/X2pPkE0nWJrkzydFD21na+j+QZGmfNUuSXmgcRxa/UVVHVtVUmz8PuK6qlgDXtXmAU4Al7bMMuBgG4QJcABwLHANcMB0wkqTxmMRpqNOBFW16BfDGofZP18DNwPwkBwEnAauqalNVPQGsAk4ec82SNKf1HRYFfDnJmiTLWtuBVfVIm34UOLBNLwQeHlp3fWvbWvvzJFmWZHWS1Rs3bpzJ3yBJc968nrf/a1W1Icm/AVYl+dbwwqqqJDUTO6qq5cBygKmpqRnZpiRpoNcji6ra0L4fB77I4JrDY+30Eu378dZ9A3Dw0OqLWtvW2iVJY9JbWCR5aZKfnp4GTgTuBlYC03c0LQWuatMrgTPbXVHHAU+101XXAicm2a9d2D6xtUmSxqTP01AHAl9MMr2f/1FVX0pyK3BFkrOBdcCbW/9rgFOBtcAzwFkAVbUpyfuAW1u/C6tqU491S5I201tYVNWDwBFbaP8OcMIW2gs4ZyvbuhS4dKZrlCSNxie4JUmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqfewyLJHkluS3J1mz80yS1J1ib5myR7tfYXt/m1bfnioW2c39rvT3JS3zVLkp5vHEcW5wL3Dc3/OfDRqno58ARwdms/G3iitX+09SPJ4cAZwCuBk4GLkuwxhrolSU2vYZFkEfBbwCfbfIDXAVe2LiuAN7bp09s8bfkJrf/pwOVV9YOqeghYCxzTZ92SpOfr+8jiY8CfAM+1+ZcBT1bVs21+PbCwTS8EHgZoy59q/X/cvoV1fizJsiSrk6zeuHHjDP8MSZrbeguLJKcBj1fVmr72MayqllfVVFVNLViwYBy7lKQ5Y16P2z4eeEOSU4G9gZ8BPg7MTzKvHT0sAja0/huAg4H1SeYB+wLfGWqfNryOJGkMRjqySLIgybuTLE9y6fRnW+tU1flVtaiqFjO4QH19Vb0VuAH4ndZtKXBVm17Z5mnLr6+qau1ntLulDgWWAN/Yjt8oSdpJox5ZXAV8FfjfwI92cp/vAi5P8n7gNuCS1n4J8Jkka4FNDAKGqronyRXAvcCzwDlVtbM1SJK2w6hhsU9VvWtHd1JVNwI3tukH2cLdTFX1feBNW1n/A8AHdnT/kqSdM+oF7qvbtQdJ0hw0alicyyAwvp/k6fb5bp+FSZJmj5FOQ1XVT/ddiCRp9hr51tkkbwBe22ZvrKqr+ylJkjTbjHrr7IcYnIq6t33OTfLBPguTJM0eox5ZnAocWVXPASRZweC21/P7KkySNHtsz3Af84em953hOiRJs9ioRxYfBG5LcgMQBtcuzuutKknSrDLq3VCfS3Ij8Kut6V1V9WhvVUmSZpVtnoZKclj7Pho4iMHw4OuBn2ttkqQ5oOvI4o+AZcB/3cKyYvAiI0nSbm6bYVFVy9rkKW3sph9LsndvVUmSZpVR74b6+ohtkqTd0DaPLJL8LINXmL4kyVEM7oSCwYuM9um5NknSLNF1zeIk4PcZvJ3uI0PtTwPv7qkmSdIs03XNYgWwIsl/qKrPj6kmSdIsM+pDea9K8srNG6vqwhmuR5I0C40aFv88NL03cBpw38yXI0majUZ9gvt5z1kk+TBwbS8VSZJmne0ZSHDYPgwuekuS5oCRjiyS3MXgiW2APYAFgNcrJGmOGPWaxWlD088Cj1XVsz3UI0mahUa9ZrGuDRz4awyOML7G4OVHkqQ5YNTXqr4HWAG8DDgAuCzJn/ZZmCRp9hj1NNRbgSOmBxNs7+S+HXh/T3VJkmaRUe+G+icGz1dMezGwYVsrJNk7yTeS3JHkniTvbe2HJrklydokf5Nkr9b+4ja/ti1fPLSt81v7/UlO2q5fKEnaaV0vP/qLJJ8AngLuSXJZkk8BdwNPdmz7B8DrquoI4Ejg5CTHAX8OfLSqXg48AZzd+p8NPNHaP9r6keRw4AzglcDJwEVJ9tjeHypJ2nFdp6FWt+81wBeH2m/s2nBVFT958nvP9pl+YdLvtvYVwJ8BFwOnt2mAK4G/TJLWfnlV/QB4KMla4Bjg/3bVIEmaGaMMJLjD2hHAGuDlwF8Bfw88OXTb7XoGQ6DTvh9u+302yVMMLqgvBG4e2uzwOsP7WsbgrX4ccsghO1O2JGkzXe+zuKKq3rzZQ3k/VlW/vK31q+pHwJFJ5jM4MjlsJ2rdpqpaDiwHmJqaekGtkqQd13Ua6tz2fdo2e3WoqieT3AC8GpifZF47uljETy6UbwAOBtYnmQfsC3xnqH3a8DqSpDHY5gXuqnqknUq6rKrWbf7Z1rpJFrQjCpK8BPhNBiPV3gD8Tuu2FLiqTa9s87Tl17frHiuBM9rdUocCS4BvbO8PlSTtuM7nLKrqR0meS7JvVT21Hds+iMGLk/ZgEEpXVNXVSe4FLk/yfgZPgV/S+l8CfKZdwN7E4A4oquqeJFcA9zIYauScdnpLkjQm2/M+i7uSrAK+N91YVX+4tRWq6k7gqC20P8jgbqbN278PvGkr2/oA8IERa5UkzbBRw+IL7TPMi8iSNEeMGhbzq+rjww1Jzt1aZ0nS7mXU4T6WbqHt92ewDknSLNb1nMVbGDxtfWiSlUOLfobBRWhJ0hzQdRrq68AjDIYlH34P99PAnX0VJUmaXbqG+1gHrEvyeuBfquq5JK9g8CT2XeMoUJI0eaNes7gJ2DvJQuDLwNuAy/oqSpI0u4waFqmqZ4B/D1xUVW9iMGS4JGkOGDkskryawRvz/q61+U4JSZojRg2LdwDnA19sw2/8AoMxniRJc8BID+VV1VeArwzNPwhsdagPSdLupes5i49V1TuS/C+2/D6LN/RWmSRp1ug6svhM+/5w34VIkmavrucs1rTvryRZ0KY3jqMwSdLs0XmBO8mfJfk2cD/w/5JsTPKe/kuTJM0W2wyLJH8EHA/8alXtX1X7AccCxyd55zgKlCRNXteRxduAt1TVQ9MN7U6o3wPO7LMwSdLs0RUWe1bVtzdvbNct9uynJEnSbNMVFj/cwWWSpN1I162zRyT57hbaA+zdQz2SpFmo69ZZx3+SJI08NpQkaQ4zLCRJnQwLSVInw0KS1MmwkCR16i0skhyc5IYk9ya5J8m5rX3/JKuSPNC+92vtSfKJJGuT3Jnk6KFtLW39H0iytK+aJUlb1ueRxbPAH1fV4cBxwDlJDgfOA66rqiXAdW0e4BRgSfssAy6GQbgAFzAYk+oY4ILpgJEkjUdvYVFVj1TVN9v008B9wELgdGBF67YCeGObPh34dA3cDMxPchBwErCqqjZV1RPAKuDkvuqWJL3QWK5ZJFkMHAXcAhxYVY+0RY8CB7bphcDDQ6utb21ba998H8uSrE6yeuNGX7khSTOp97BI8lPA54F3VNXzhg6pqmILr2vdEVW1vKqmqmpqwYIFM7FJSVLTa1gk2ZNBUHy2qr7Qmh9rp5do34+39g3AwUOrL2ptW2uXJI1Jn3dDBbgEuK+qPjK0aCUwfUfTUuCqofYz211RxwFPtdNV1wInJtmvXdg+sbVJksaka9TZnXE8g5cn3ZXk9tb2buBDwBVJzgbWAW9uy64BTgXWAs8AZwFU1aYk7wNubf0urKpNPdYtSdpMb2FRVV9jMJT5lpywhf4FnLOVbV0KXDpz1UmStodPcEuSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOvUWFkkuTfJ4kruH2vZPsirJA+17v9aeJJ9IsjbJnUmOHlpnaev/QJKlfdUrSdq6Po8sLgNO3qztPOC6qloCXNfmAU4BlrTPMuBiGIQLcAFwLHAMcMF0wEiSxqe3sKiqm4BNmzWfDqxo0yuANw61f7oGbgbmJzkIOAlYVVWbquoJYBUvDCBJUs9SVf1tPFkMXF1Vr2rzT1bV/DYd4Imqmp/kauBDVfW1tuw64F3ArwN7V9X7W/t/Bv6lqj68hX0tY3BUwiGHHPIr69at24m6d3jVkWzrP/nuvO9t7d99u2/33e++R5FkTVVNbWnZxC5w1yClZiypqmp5VU1V1dSCBQtmarOSJMYfFo+100u078db+wbg4KF+i1rb1tolSWM07rBYCUzf0bQUuGqo/cx2V9RxwFNV9QhwLXBikv3ahe0TW5skaYzm9bXhJJ9jcM3hgCTrGdzV9CHgiiRnA+uAN7fu1wCnAmuBZ4CzAKpqU5L3Abe2fhdW1eYXzSVJPev1AvekTE1N1erVq3d4/d35IrMXuN23+56b+x7FrLzALUnadRgWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROu0xYJDk5yf1J1iY5b9L1SNJcskuERZI9gL8CTgEOB96S5PDJViVJc8cuERbAMcDaqnqwqn4IXA6cPuGaJGnOmDfpAka0EHh4aH49cOxwhyTLgGVt9p+T3D+m2gAOAL49auekx0rGu+/t+t097H+7zOC+/d3j3/d283fvkJ/f2oJdJSw6VdVyYPkk9p1kdVVNTWLfk+Tvnlv83XPbrnIaagNw8ND8otYmSRqDXSUsbgWWJDk0yV7AGcDKCdckSXPGLnEaqqqeTfKfgGuBPYBLq+qeCZc1bCKnv2YBf/fc4u+ew1JVk65BkjTL7SqnoSRJE2RYSJI6GRY7Ya4OQZLk4CQ3JLk3yT1Jzp10TeOUZI8ktyW5etK1jEuS+UmuTPKtJPclefWkaxqHJO9sf8bvTvK5JHtPuqZJMSx20BwfguRZ4I+r6nDgOOCcOfTbAc4F7pt0EWP2ceBLVXUYcARz4PcnWQj8ITBVVa9icHPNGZOtanIMix03Z4cgqapHquqbbfppBn9xLJxsVeORZBHwW8AnJ13LuCTZF3gtcAlAVf2wqp6caFHjMw94SZJ5wD7AP024nokxLHbcloYgmRN/YQ5Lshg4CrhlwqWMy8eAPwGem3Ad43QosBH4VDv99skkL510UX2rqg3Ah4F/BB4BnqqqL0+2qskxLLTDkvwU8HngHVX13UnX07ckpwGPV9WaSdcyZvOAo4GLq+oo4HvAbn+NLsl+DM4WHAr8HPDSJL832aomx7DYcXN6CJIkezIIis9W1RcmXc+YHA+8Ick/MDjt+Lokfz3ZksZiPbC+qqaPHq9kEB67u9cDD1XVxqr6V+ALwGsmXNPEGBY7bs4OQZIkDM5f31dVH5l0PeNSVedX1aKqWszg//f1VbXb/0uzqh4FHk7yS63pBODeCZY0Lv8IHJdkn/Zn/gTmwIX9rdklhvuYjXaBIUj6dDzwNuCuJLe3tndX1TWTK0k9+wPgs+0fRg8CZ024nt5V1S1JrgS+yeAOwNuYw0N/ONyHJKmTp6EkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtpREl+NsnlSf4+yZok1yR5RZK7J12b1Defs5BG0B7K+iKwoqrOaG1HAAdOtDBpTDyykEbzG8C/VtV/m26oqjsYGkwyyeIkX03yzfZ5TWs/KMlNSW5v70X4d+2dGJe1+buSvLP1/cUkX2pHLl9Nclhrf1Pre0eSm8b70yWPLKRRvQroGkDwceA3q+r7SZYAnwOmgN8Frq2qD7T3oOwDHAksbO9JIMn8to3lwNur6oEkxwIXAa8D3gOcVFUbhvpKY2NYSDNnT+AvkxwJ/Ah4RWu/Fbi0Db74P6vq9iQPAr+Q5C+AvwO+3EbxfQ3wt4OzXgC8uH3/H+CyJFcwGNBOGitPQ0mjuQf4lY4+7wQeY/AmuSlgL4CquonBy4M2MPgL/8yqeqL1uxF4O4OXKb0IeLKqjhz6/Nu2jbcDf8pgpOM1SV42w79P2ibDQhrN9cCLkyybbkjyyzx/mPp9gUeq6jkGAy3u0fr9PPBYVf13BqFwdJIDgBdV1ecZhMDR7Z0gDyV5U1sv7SI6SX6xqm6pqvcweBHR8H6l3hkW0ghqMOLmbwOvb7fO3gN8EHh0qNtFwNIkdwCHMXhJEMCvA3ckuQ34jwzeZ70QuLGN2vvXwPmt71uBs9s27uEnr+r9L+1C+N3A14E7evmh0lY46qwkqZNHFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSer0/wGVVHO0VBZRlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "trL = pd.DataFrame(trainLabels,dtype = int)\n",
    "teL = pd.DataFrame(testLabels,dtype = int)\n",
    "\n",
    "x = list(range(N_CLASSES))\n",
    "plt.bar(x, trL.value_counts(), color=\"purple\")\n",
    "plt.bar(x, teL.value_counts(), color=\"blue\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Third step is to normalize data. Every number of the data is between 0 to 255 so to normalize them, they are divided by 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = np.genfromtxt(\"testData.csv\", delimiter = ',')\n",
    "testLabels = np.genfromtxt(\"testLabels.csv\", delimiter = ',')\n",
    "\n",
    "trainData = np.matrix(trainData, dtype = float)\n",
    "testData = np.matrix(testData, dtype = float)\n",
    "\n",
    "trainLabels = np.matrix(trainLabels, dtype = int).transpose()\n",
    "testLabels = np.matrix(testLabels, dtype = int).transpose()\n",
    "\n",
    "trainData = trainData/256\n",
    "testData = testData/256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementing Neural Network </h3>\n",
    "<p>Here is the implementation of the neural network.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dataloader</h3>\n",
    "<p>First data loader class is defined. This class gets data, labels, number of classes, batch size and shuffle and it basically load the data. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self, data, labels, n_classes, batch_size=None, shuffle=False):\n",
    "\n",
    "        assert len(data)==len(labels)\n",
    "        self.__n_classes = n_classes\n",
    "        self.__batch_size = batch_size\n",
    "        self.__shuffle = shuffle\n",
    "        self.__data = data\n",
    "        self.__onehot_labels = self.__onehot(labels, self.__n_classes)\n",
    "    \n",
    "    def __onehot(self, labels, n_classes):\n",
    "        # TODO: Implement\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        onehot_vectors = np.matrix(onehot_encoder.fit_transform(labels),dtype=float)\n",
    "        return onehot_vectors\n",
    "    \n",
    "    def __shuffle_dataset(self):\n",
    "        # TODO: Implement\n",
    "        order = np.random.permutation(len(self.__data))\n",
    "        self.__data = self.__data[order]\n",
    "        self.__onehot_labels = self.__onehot_labels[order]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.__shuffle:\n",
    "            self.__shuffle_dataset()\n",
    "            \n",
    "        if self.__batch_size==None:\n",
    "            yield (np.matrix(self.__data), np.matrix(self.__onehot_labels))\n",
    "            return\n",
    "            \n",
    "        for idx in range(0, len(self.__data), self.__batch_size):\n",
    "            yield (np.matrix(self.__data[idx:idx+self.__batch_size]), \n",
    "                   np.matrix(self.__onehot_labels[idx:idx+self.__batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Activation Functions</h3>\n",
    "<p>This is the implementation of several activation functions: Identical, Relu, Leaky Relu, Sigmoid and Softmax.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identical:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        identical_value = np.matrix(matrix, dtype=float)\n",
    "        return identical_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
    "        return identical_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "\n",
    "class Relu:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __relu(self, matrix):\n",
    "        relu_value = np.matrix(matrix, dtype = float)\n",
    "        relu_value[relu_value < 0] = 0 \n",
    "        return relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        relu_derivative = np.matrix(matrix, dtype = float)\n",
    "        relu_derivative[relu_derivative < 0] = 0\n",
    "        relu_derivative[relu_derivative > 0] = 1\n",
    "        return relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__relu(matrix)\n",
    "\n",
    "    \n",
    "class LeakyRelu:\n",
    "    \n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        self.negative_slope = negative_slope\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        # TODO: Implement\n",
    "        leaky_relu_value = np.matrix(matrix, dtype = float).copy()\n",
    "        leaky_relu_value = np.where(leaky_relu_value < 0, self.negative_slope * leaky_relu_value, leaky_relu_value)\n",
    "        return leaky_relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        # TODO: Implement\n",
    "        leaky_relu_derivative = np.matrix(matrix, dtype = float).copy()\n",
    "        leaky_relu_derivative[leaky_relu_derivative >= 0] = 1\n",
    "        leaky_relu_derivative[leaky_relu_derivative < 0] = self.negative_slope\n",
    "        return leaky_relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        # TODO: Implement\n",
    "        sigmoid_value = np.matrix(1/(1+np.exp(-matrix)),dtype = float)\n",
    "        return sigmoid_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        # TODO: Implement\n",
    "        sigmoid_derivative = np.multiply(self.__val(matrix) ,(1-self.__val(matrix)))\n",
    "        return sigmoid_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        shifted_matrix = matrix - matrix.max()\n",
    "        expo = np.exp(shifted_matrix)\n",
    "        expo_sum = np.sum(np.exp(shifted_matrix))\n",
    "        softmax_value = expo / expo_sum\n",
    "        return softmax_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        softmax_derivative = 1 / (1+np.exp(-matrix))\n",
    "        return softmax_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Loss Function</h3>\n",
    "<p> Loss function in this project is Cross Entropy. The activation function of the last layer is softmax to make the implementation and calculation of the derivation simpler.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy: #(with softmax)\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        softmax = Softmax()\n",
    "        softmax_out = np.matrix(true_val)\n",
    "        for i in range(len(true_val)):\n",
    "            softmax_out[i] = softmax(true_val[i])\n",
    "        cross_entropy_value = np.matrix(- np.array(expected_val)* np.log(np.array(softmax_out)))\n",
    "        return cross_entropy_value\n",
    "        \n",
    "    def derivative(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        softmax = Softmax()\n",
    "        softmax_out = np.matrix(true_val)\n",
    "        for i in range(len(true_val)):\n",
    "            softmax_out[i] = softmax(true_val[i])\n",
    "        cross_entropy_derivative = softmax_out - expected_val\n",
    "        return cross_entropy_derivative\n",
    "    \n",
    "    def __call__(self, true_val, expected_val):\n",
    "        return self.__val(true_val, expected_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Layer</h3>\n",
    "<p>In each layer, there is a forward function that stores last input, last input of the activation function of the layer, last output of the activation of the layer and the last calculated derivative of the activation of the layer. <br> In update weights function, the weights and biases of the layer will be updated.<br>Uniform weight and normal weight are the functions that calculate the initial weights of the layer randomly.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, DEFAULT_VAR = 0, 0.05, 0., 1.\n",
    "  \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=Identical(), initial_weight='uniform', **initializing_parameters):\n",
    "\n",
    "        \n",
    "        assert type(initial_weight)==str, 'Undefined activation function!'\n",
    "        \n",
    "        self.__weight_initializer_dict = {'uniform':self.__uniform_weight, 'normal':self.__normal_weight}\n",
    "        \n",
    "        self.__n_neurons = output_size\n",
    "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
    "        self.__weight = weight_initializer(input_size, self.__n_neurons, **initializing_parameters)\n",
    "        self.__bias = weight_initializer(1, self.__n_neurons, **initializing_parameters)\n",
    "        self.__activation = activation\n",
    "        \n",
    "        self.__last_input = None\n",
    "        self.__last_activation_input = None\n",
    "        self.__last_activation_output = None\n",
    "        self.__last_activation_derivative = None\n",
    "        \n",
    "    def forward(self, layer_input):\n",
    "        assert np.ndim(layer_input)==2\n",
    "        assert np.size(self.__weight,0) == np.size(layer_input,1)\n",
    "        # TODO: Implement\n",
    "        self.__last_input = layer_input\n",
    "        self.__last_activation_input = np.matmul(self.__last_input,self.__weight) + self.__bias\n",
    "        self.__last_activation_output = self.__activation(self.__last_activation_input)\n",
    "        self.__last_activation_derivative = self.__activation.derivative(self.__last_activation_input)\n",
    "        return self.__last_activation_output\n",
    "    \n",
    "    def update_weights(self, backprop_tensor, lr):\n",
    "        assert np.ndim(backprop_tensor)==2\n",
    "        assert np.size(backprop_tensor,0) == np.size(self.__last_activation_derivative,0)\n",
    "        assert np.size(backprop_tensor,1) == self.__n_neurons\n",
    "        # TODO: Implement\n",
    "        grad_l_a = np.multiply(backprop_tensor , self.__last_activation_derivative)\n",
    "        grad_l_w = np.matmul(self.__last_input.transpose(), grad_l_a)\n",
    "        backprop_tensor = np.matmul(grad_l_a,self.__weight.transpose())\n",
    "        self.__weight = self.__weight - lr*grad_l_w\n",
    "        self.__bias = self.__bias - lr*grad_l_a.sum(axis=0)\n",
    "        \n",
    "        return backprop_tensor\n",
    "\n",
    "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
    "        if 'low' in initializing_parameters.keys(): low = initializing_parameters['low']\n",
    "        if 'high' in initializing_parameters.keys(): high = initializing_parameters['high']\n",
    "        # TODO: Implement\n",
    "        weights = np.random.uniform(low,high,size = (dim1,dim2))\n",
    "        return weights\n",
    "\n",
    "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
    "        if 'mean' in initializing_parameters.keys(): mean = initializing_parameters['mean']\n",
    "        if 'var' in initializing_parameters.keys(): var = initializing_parameters['var']\n",
    "        # TODO: Implement\n",
    "        weights = np.random.normal(mean, np.sqrt(var), size = (dim1,dim2))\n",
    "        return weights\n",
    "    \n",
    "    @property\n",
    "    def n_neurons(self): return self.__n_neurons\n",
    "    \n",
    "    @property\n",
    "    def weight(self): return self.__weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self): return self.__bias\n",
    "    \n",
    "    @property\n",
    "    def activation(self): return self.__activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feed Forward Neural Network</h3>\n",
    "<p>Here is the main class of the Feed Forward Neural Network. The training and back propagation of the Network accursed in this class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "        \n",
    "        self.__layers_list = []\n",
    "        \n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "\n",
    "        \n",
    "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):\n",
    "         \n",
    "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
    "        \n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
    "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
    "        self.__layers_list.append(new_layer)\n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
    "      \n",
    "    \n",
    "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
    "        assert self.__layers_list, \"Uncomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = lr\n",
    "    \n",
    "    def output2D(self, inputloader):\n",
    "        for x_input, y_input in inputloader:\n",
    "            assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "            layer_input = x_input\n",
    "            i = 0\n",
    "            for layer in self.__layers_list:\n",
    "                network_output = layer.forward(layer_input)\n",
    "                if(i == len(self.__layers_list)-2):\n",
    "                    return network_output\n",
    "                layer_input = network_output\n",
    "                i+=1\n",
    "        \n",
    "    def forward(self, network_input):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        # TODO: Implement\n",
    "        layer_input = network_input\n",
    "        for layer in self.__layers_list:\n",
    "            network_output = layer.forward(layer_input)\n",
    "            layer_input = network_output\n",
    "        return network_output\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
    "        \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            if print_results: \n",
    "                print('Epoch {}:'.format(epoch)) \n",
    "                \n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "            \n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "                    \n",
    "        return log\n",
    "    \n",
    "    \n",
    "    def __train(self, trainloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_train, y_train in trainloader:\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "    \n",
    "    \n",
    "    def __test(self, testloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    \n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        # TODO: Implement\n",
    "        batch_out = self.forward(x_batch)\n",
    "        batch_losses = []\n",
    "        labels = self.__get_labels(batch_out)\n",
    "        batch_losses = self.__loss(labels, y_batch)\n",
    "        batch_average_loss = sum(batch_losses)/len(x_batch)\n",
    "        batch_accuracy = self.__compute_accuracy(labels,y_batch)\n",
    "        self.__update_weights(batch_out, y_batch)\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "        \n",
    "        \n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        # TODO: Implement\n",
    "        batch_out = self.forward(x_batch)\n",
    "        batch_losses = []\n",
    "        labels = self.__get_labels(batch_out)\n",
    "        batch_losses = self.__loss(labels, y_batch)\n",
    "        batch_average_loss = sum(batch_losses)/len(x_batch)\n",
    "        batch_accuracy = self.__compute_accuracy(labels,y_batch)\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "    \n",
    "    def __get_labels(self, outputs):\n",
    "        # TODO: Implement\n",
    "        labels = outputs.copy()\n",
    "        for label in labels:\n",
    "            ind = np.argmax(label)\n",
    "            label.fill(0)\n",
    "            label[0,ind] = 1.\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "        # TODO: Implement\n",
    "        correct = 0\n",
    "        for i in range(len(output)):\n",
    "            label_out = np.argmax(output[i])\n",
    "            label_expected = np.argmax(expected_output[i])\n",
    "            if(label_out == label_expected): correct += 1\n",
    "        accuracy = correct /len(expected_output)\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def __update_weights(self, output, y_train):\n",
    "        # TODO: Implement\n",
    "        backprop_tensor = self.__loss.derivative(output,y_train)\n",
    "        for layer in reversed(self.__layers_list):\n",
    "            backprop_tensor = layer.update_weights(backprop_tensor, self.__lr)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Classification </h3>\n",
    "<h4>Step 1:</h4> <p>A neural network with at least two hidden layers and the hyper parameters shown below:</h4>\n",
    "    Batch Size = 32<br>Number of Training Epochs = 30 <br> Activation Function = Relu<br> Weight Initialization = Uniform or Normal</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.5918166666666667\tAverage Loss: 0.18693335050678078\n",
      "\tTest: Average Accuracy: 0.7652755591054313\tAverage Loss: 0.16958746126290436\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8061833333333334\tAverage Loss: 0.16549668384011412\n",
      "\tTest: Average Accuracy: 0.8120007987220448\tAverage Loss: 0.16491493730124301\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8342833333333334\tAverage Loss: 0.16268668384011412\n",
      "\tTest: Average Accuracy: 0.8243809904153354\tAverage Loss: 0.16367691813191396\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8450333333333333\tAverage Loss: 0.16161168384011412\n",
      "\tTest: Average Accuracy: 0.8311701277955271\tAverage Loss: 0.16299800439389478\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8518666666666667\tAverage Loss: 0.16092835050678078\n",
      "\tTest: Average Accuracy: 0.8373602236421726\tAverage Loss: 0.16237899480923024\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8568666666666667\tAverage Loss: 0.16042835050678078\n",
      "\tTest: Average Accuracy: 0.8422523961661342\tAverage Loss: 0.16188977755683406\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8609833333333333\tAverage Loss: 0.16001668384011414\n",
      "\tTest: Average Accuracy: 0.8485423322683706\tAverage Loss: 0.16126078394661042\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8643166666666666\tAverage Loss: 0.15968335050678079\n",
      "\tTest: Average Accuracy: 0.8526357827476039\tAverage Loss: 0.1608514388986871\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.86795\tAverage Loss: 0.15932001717344746\n",
      "\tTest: Average Accuracy: 0.8559305111821086\tAverage Loss: 0.16052196605523664\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.86955\tAverage Loss: 0.15916001717344747\n",
      "\tTest: Average Accuracy: 0.8558306709265175\tAverage Loss: 0.16053195008079574\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8722333333333333\tAverage Loss: 0.15889168384011412\n",
      "\tTest: Average Accuracy: 0.8572284345047924\tAverage Loss: 0.16039217372296827\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8749333333333333\tAverage Loss: 0.15862168384011413\n",
      "\tTest: Average Accuracy: 0.8599241214057508\tAverage Loss: 0.1601226050328724\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8776\tAverage Loss: 0.15835501717344747\n",
      "\tTest: Average Accuracy: 0.8601238019169329\tAverage Loss: 0.1601026369817542\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.87955\tAverage Loss: 0.15816001717344746\n",
      "\tTest: Average Accuracy: 0.860223642172524\tAverage Loss: 0.1600926529561951\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8809833333333333\tAverage Loss: 0.15801668384011414\n",
      "\tTest: Average Accuracy: 0.8623202875399361\tAverage Loss: 0.1598829884194539\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8823\tAverage Loss: 0.15788501717344747\n",
      "\tTest: Average Accuracy: 0.8609225239616614\tAverage Loss: 0.16002276477728136\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8832166666666666\tAverage Loss: 0.15779335050678078\n",
      "\tTest: Average Accuracy: 0.8627196485623003\tAverage Loss: 0.15984305231721746\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8849\tAverage Loss: 0.15762501717344746\n",
      "\tTest: Average Accuracy: 0.8627196485623003\tAverage Loss: 0.15984305231721746\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8859166666666667\tAverage Loss: 0.1575233505067808\n",
      "\tTest: Average Accuracy: 0.8629193290734825\tAverage Loss: 0.15982308426609926\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8871166666666667\tAverage Loss: 0.15740335050678078\n",
      "\tTest: Average Accuracy: 0.8651158146964856\tAverage Loss: 0.15960343570379892\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8882833333333333\tAverage Loss: 0.15728668384011413\n",
      "\tTest: Average Accuracy: 0.8652156549520766\tAverage Loss: 0.15959345167823982\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8897833333333334\tAverage Loss: 0.15713668384011412\n",
      "\tTest: Average Accuracy: 0.8655151757188498\tAverage Loss: 0.15956349960156252\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8912166666666667\tAverage Loss: 0.1569933505067808\n",
      "\tTest: Average Accuracy: 0.8653154952076677\tAverage Loss: 0.15958346765268072\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.89205\tAverage Loss: 0.15691001717344746\n",
      "\tTest: Average Accuracy: 0.8652156549520766\tAverage Loss: 0.15959345167823982\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8924333333333333\tAverage Loss: 0.15687168384011413\n",
      "\tTest: Average Accuracy: 0.865814696485623\tAverage Loss: 0.1595335475248852\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8936\tAverage Loss: 0.15675501717344748\n",
      "\tTest: Average Accuracy: 0.865714856230032\tAverage Loss: 0.1595435315504443\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.89455\tAverage Loss: 0.15666001717344746\n",
      "\tTest: Average Accuracy: 0.8665135782747604\tAverage Loss: 0.15946365934597145\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8953833333333333\tAverage Loss: 0.15657668384011414\n",
      "\tTest: Average Accuracy: 0.8673123003194888\tAverage Loss: 0.15938378714149862\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8962666666666667\tAverage Loss: 0.15648835050678078\n",
      "\tTest: Average Accuracy: 0.8671126198083067\tAverage Loss: 0.15940375519261682\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8971833333333333\tAverage Loss: 0.15639668384011413\n",
      "\tTest: Average Accuracy: 0.8675119808306709\tAverage Loss: 0.1593638190903804\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_SHAPE = 784\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 30\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 32)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 32)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 2:</h4> \n",
    "<p>By multiplaying learning rate 10 times the train accuracy is better in the first few times and by multiplaying learning rate 1/10 times, the train accuracy is lower in the first few epochs. After several epochs the train accuracy of both cases are very close.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.58105\tAverage Loss: 0.18801001717344745\n",
      "\tTest: Average Accuracy: 0.586361821086262\tAverage Loss: 0.1874788350648213\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.73295\tAverage Loss: 0.17282001717344747\n",
      "\tTest: Average Accuracy: 0.7207468051118211\tAverage Loss: 0.17404033666226537\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.7938666666666667\tAverage Loss: 0.16672835050678078\n",
      "\tTest: Average Accuracy: 0.7928314696485623\tAverage Loss: 0.16683187020859128\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.82355\tAverage Loss: 0.16376001717344746\n",
      "\tTest: Average Accuracy: 0.8230830670926518\tAverage Loss: 0.16380671046418233\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8347166666666667\tAverage Loss: 0.1626433505067808\n",
      "\tTest: Average Accuracy: 0.8267771565495208\tAverage Loss: 0.16343730151849542\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8419333333333333\tAverage Loss: 0.16192168384011413\n",
      "\tTest: Average Accuracy: 0.8184904153354633\tAverage Loss: 0.16426597563990117\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8482\tAverage Loss: 0.16129501717344746\n",
      "\tTest: Average Accuracy: 0.8383586261980831\tAverage Loss: 0.1622791545536392\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8523333333333334\tAverage Loss: 0.16088168384011411\n",
      "\tTest: Average Accuracy: 0.821685303514377\tAverage Loss: 0.1639464868220098\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8553\tAverage Loss: 0.16058501717344748\n",
      "\tTest: Average Accuracy: 0.832867412140575\tAverage Loss: 0.16282827595938998\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8574666666666667\tAverage Loss: 0.1603683505067808\n",
      "\tTest: Average Accuracy: 0.838158945686901\tAverage Loss: 0.1622991226047574\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8581166666666666\tAverage Loss: 0.1603033505067808\n",
      "\tTest: Average Accuracy: 0.8357627795527156\tAverage Loss: 0.16253873921817594\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8628666666666667\tAverage Loss: 0.1598283505067808\n",
      "\tTest: Average Accuracy: 0.8393570287539937\tAverage Loss: 0.16217931429804813\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8639333333333333\tAverage Loss: 0.15972168384011412\n",
      "\tTest: Average Accuracy: 0.8329672523961661\tAverage Loss: 0.16281829193383088\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8665333333333334\tAverage Loss: 0.15946168384011414\n",
      "\tTest: Average Accuracy: 0.8395567092651757\tAverage Loss: 0.16215934624692993\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8671833333333333\tAverage Loss: 0.15939668384011413\n",
      "\tTest: Average Accuracy: 0.8405551118210862\tAverage Loss: 0.16205950599133886\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8691666666666666\tAverage Loss: 0.1591983505067808\n",
      "\tTest: Average Accuracy: 0.8412539936102237\tAverage Loss: 0.16198961781242513\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.87055\tAverage Loss: 0.15906001717344745\n",
      "\tTest: Average Accuracy: 0.8393570287539937\tAverage Loss: 0.16217931429804813\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.87185\tAverage Loss: 0.15893001717344746\n",
      "\tTest: Average Accuracy: 0.8386581469648562\tAverage Loss: 0.16224920247696187\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8721333333333333\tAverage Loss: 0.15890168384011413\n",
      "\tTest: Average Accuracy: 0.8278753993610224\tAverage Loss: 0.16332747723734525\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.87225\tAverage Loss: 0.15889001717344747\n",
      "\tTest: Average Accuracy: 0.8447484025559105\tAverage Loss: 0.16164017691785643\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8732833333333333\tAverage Loss: 0.15878668384011413\n",
      "\tTest: Average Accuracy: 0.8453474440894568\tAverage Loss: 0.1615802727645018\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8752333333333333\tAverage Loss: 0.15859168384011413\n",
      "\tTest: Average Accuracy: 0.8387579872204473\tAverage Loss: 0.16223921845140277\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.87485\tAverage Loss: 0.15863001717344746\n",
      "\tTest: Average Accuracy: 0.8388578274760383\tAverage Loss: 0.16222923442584367\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.87725\tAverage Loss: 0.15839001717344747\n",
      "\tTest: Average Accuracy: 0.8337659744408946\tAverage Loss: 0.16273841972935804\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8767666666666667\tAverage Loss: 0.1584383505067808\n",
      "\tTest: Average Accuracy: 0.8315694888178914\tAverage Loss: 0.16295806829165835\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8791333333333333\tAverage Loss: 0.15820168384011413\n",
      "\tTest: Average Accuracy: 0.8369608626198083\tAverage Loss: 0.16241893091146667\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8798333333333334\tAverage Loss: 0.15813168384011414\n",
      "\tTest: Average Accuracy: 0.832667731629393\tAverage Loss: 0.1628482440105082\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8805833333333334\tAverage Loss: 0.15805668384011412\n",
      "\tTest: Average Accuracy: 0.8346645367412141\tAverage Loss: 0.16264856349932608\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8800166666666667\tAverage Loss: 0.1581133505067808\n",
      "\tTest: Average Accuracy: 0.8273761980830671\tAverage Loss: 0.1633773973651408\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8804\tAverage Loss: 0.15807501717344746\n",
      "\tTest: Average Accuracy: 0.8276757188498403\tAverage Loss: 0.16334744528846346\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 32)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 32)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.14655\tAverage Loss: 0.23146001717344747\n",
      "\tTest: Average Accuracy: 0.2299321086261981\tAverage Loss: 0.22312180631082768\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.4135\tAverage Loss: 0.20476501717344744\n",
      "\tTest: Average Accuracy: 0.4665535143769968\tAverage Loss: 0.1994596657357478\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.5280333333333334\tAverage Loss: 0.19331168384011413\n",
      "\tTest: Average Accuracy: 0.575279552715655\tAverage Loss: 0.18858706190188199\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.6517\tAverage Loss: 0.18094501717344746\n",
      "\tTest: Average Accuracy: 0.6810103833865815\tAverage Loss: 0.17801397883478934\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.6992833333333334\tAverage Loss: 0.17618668384011413\n",
      "\tTest: Average Accuracy: 0.7074680511182109\tAverage Loss: 0.1753682120616264\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7261\tAverage Loss: 0.17350501717344746\n",
      "\tTest: Average Accuracy: 0.7299321086261981\tAverage Loss: 0.17312180631082769\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.7487166666666667\tAverage Loss: 0.1712433505067808\n",
      "\tTest: Average Accuracy: 0.7523961661341853\tAverage Loss: 0.17087540056002895\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.7661666666666667\tAverage Loss: 0.1694983505067808\n",
      "\tTest: Average Accuracy: 0.7643769968051118\tAverage Loss: 0.1696773174929363\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.7792833333333333\tAverage Loss: 0.16818668384011412\n",
      "\tTest: Average Accuracy: 0.7734624600638977\tAverage Loss: 0.1687687711670577\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.7894\tAverage Loss: 0.16717501717344746\n",
      "\tTest: Average Accuracy: 0.7822484025559105\tAverage Loss: 0.16789017691785643\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.79835\tAverage Loss: 0.16628001717344745\n",
      "\tTest: Average Accuracy: 0.7887380191693291\tAverage Loss: 0.16724121525651459\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.80445\tAverage Loss: 0.16567001717344745\n",
      "\tTest: Average Accuracy: 0.796026357827476\tAverage Loss: 0.16651238139069988\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.81105\tAverage Loss: 0.16501001717344746\n",
      "\tTest: Average Accuracy: 0.8018170926517572\tAverage Loss: 0.16593330790827177\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8171833333333334\tAverage Loss: 0.16439668384011413\n",
      "\tTest: Average Accuracy: 0.8052116613418531\tAverage Loss: 0.1655938510392622\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8223666666666667\tAverage Loss: 0.1638783505067808\n",
      "\tTest: Average Accuracy: 0.8094049520766773\tAverage Loss: 0.16517452196577975\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8259666666666666\tAverage Loss: 0.1635183505067808\n",
      "\tTest: Average Accuracy: 0.8137979233226837\tAverage Loss: 0.1647352248411791\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8297333333333333\tAverage Loss: 0.16314168384011413\n",
      "\tTest: Average Accuracy: 0.8157947284345048\tAverage Loss: 0.164535544329997\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8321\tAverage Loss: 0.16290501717344746\n",
      "\tTest: Average Accuracy: 0.8208865814696485\tAverage Loss: 0.16402635902648263\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8350666666666666\tAverage Loss: 0.1626083505067808\n",
      "\tTest: Average Accuracy: 0.8236821086261981\tAverage Loss: 0.1637468063108277\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8372666666666667\tAverage Loss: 0.1623883505067808\n",
      "\tTest: Average Accuracy: 0.8265774760383386\tAverage Loss: 0.16345726956961362\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8392166666666667\tAverage Loss: 0.1621933505067808\n",
      "\tTest: Average Accuracy: 0.827176517571885\tAverage Loss: 0.163397365416259\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8415833333333333\tAverage Loss: 0.16195668384011414\n",
      "\tTest: Average Accuracy: 0.8282747603833865\tAverage Loss: 0.16328754113510882\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8432333333333333\tAverage Loss: 0.16179168384011414\n",
      "\tTest: Average Accuracy: 0.8297723642172524\tAverage Loss: 0.16313778075172225\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8449333333333333\tAverage Loss: 0.16162168384011413\n",
      "\tTest: Average Accuracy: 0.830970447284345\tAverage Loss: 0.16301797244501298\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8458333333333333\tAverage Loss: 0.16153168384011413\n",
      "\tTest: Average Accuracy: 0.8325678913738019\tAverage Loss: 0.1628582280360673\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.84705\tAverage Loss: 0.16141001717344747\n",
      "\tTest: Average Accuracy: 0.8330670926517572\tAverage Loss: 0.16280830790827178\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8481833333333333\tAverage Loss: 0.16129668384011414\n",
      "\tTest: Average Accuracy: 0.834564696485623\tAverage Loss: 0.1626585475248852\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8491833333333333\tAverage Loss: 0.16119668384011412\n",
      "\tTest: Average Accuracy: 0.8350638977635783\tAverage Loss: 0.16260862739708967\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8501166666666666\tAverage Loss: 0.1611033505067808\n",
      "\tTest: Average Accuracy: 0.8358626198083067\tAverage Loss: 0.1625287551926168\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8511166666666666\tAverage Loss: 0.1610033505067808\n",
      "\tTest: Average Accuracy: 0.836361821086262\tAverage Loss: 0.1624788350648213\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 32)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 32)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 3:</h4> \n",
    "<p>Here The Neural Network is designed with different activation functions.<br> The advantage of LeakyRelu over Relu is due top some Relu neurons essentially die for all inputs and remain inactive no matter what input is supplied. So here no gradient flows and if large number of dead neurons are there in a Neural Network its performance is affected. But leakyRelu extend the range of the relu by having a slope and not being zero at negative values. <br> Sigmoid function and its derivative is simple and helps in reducing time required for making models. But there is a major drawback of info loss due to the derivative having a short range. In another word, The output of sigmoid saturates for a large numbers. Thus, the gradient at these regions is almost zero.<br>Another drawback of the sigmoid function is that sigmoid outputs are not zero-centered, which is undesirable because it can indirectly introduce undesirable zig-zagging dynamics in the gradient updates for the weights.</p>\n",
    "<p>From now on, leaky relu is the activation function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.5991666666666666\tAverage Loss: 0.1861983505067808\n",
      "\tTest: Average Accuracy: 0.7674720447284346\tAverage Loss: 0.16936781270060405\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8050666666666667\tAverage Loss: 0.1656083505067808\n",
      "\tTest: Average Accuracy: 0.8085063897763578\tAverage Loss: 0.16526437819581172\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8320166666666666\tAverage Loss: 0.1629133505067808\n",
      "\tTest: Average Accuracy: 0.8210862619808307\tAverage Loss: 0.16400639097536443\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8435666666666667\tAverage Loss: 0.1617583505067808\n",
      "\tTest: Average Accuracy: 0.8287739616613419\tAverage Loss: 0.16323762100731332\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8519166666666667\tAverage Loss: 0.1609233505067808\n",
      "\tTest: Average Accuracy: 0.8349640575079872\tAverage Loss: 0.16261861142264877\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8573666666666667\tAverage Loss: 0.1603783505067808\n",
      "\tTest: Average Accuracy: 0.8401557507987221\tAverage Loss: 0.1620994420935753\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8608666666666667\tAverage Loss: 0.1600283505067808\n",
      "\tTest: Average Accuracy: 0.8445487220447284\tAverage Loss: 0.16166014496897466\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.86405\tAverage Loss: 0.15971001717344746\n",
      "\tTest: Average Accuracy: 0.849241214057508\tAverage Loss: 0.16119089576769668\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8671\tAverage Loss: 0.15940501717344746\n",
      "\tTest: Average Accuracy: 0.8520367412140575\tAverage Loss: 0.16091134305204174\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8701333333333333\tAverage Loss: 0.15910168384011414\n",
      "\tTest: Average Accuracy: 0.8533346645367412\tAverage Loss: 0.16078155071977338\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8722333333333333\tAverage Loss: 0.15889168384011412\n",
      "\tTest: Average Accuracy: 0.8553314696485623\tAverage Loss: 0.16058187020859127\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8743833333333333\tAverage Loss: 0.15867668384011413\n",
      "\tTest: Average Accuracy: 0.8568290734824281\tAverage Loss: 0.16043210982520467\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8764833333333333\tAverage Loss: 0.15846668384011414\n",
      "\tTest: Average Accuracy: 0.8570287539936102\tAverage Loss: 0.16041214177408647\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8785333333333334\tAverage Loss: 0.15826168384011413\n",
      "\tTest: Average Accuracy: 0.8600239616613419\tAverage Loss: 0.1601126210073133\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8809333333333333\tAverage Loss: 0.15802168384011414\n",
      "\tTest: Average Accuracy: 0.860323482428115\tAverage Loss: 0.160082668930636\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8821833333333333\tAverage Loss: 0.15789668384011413\n",
      "\tTest: Average Accuracy: 0.8619209265175719\tAverage Loss: 0.1599229245216903\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8840166666666667\tAverage Loss: 0.1577133505067808\n",
      "\tTest: Average Accuracy: 0.8635183706070287\tAverage Loss: 0.15976318011274462\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8853833333333333\tAverage Loss: 0.15757668384011414\n",
      "\tTest: Average Accuracy: 0.8630191693290735\tAverage Loss: 0.15981310024054016\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8868333333333334\tAverage Loss: 0.15743168384011413\n",
      "\tTest: Average Accuracy: 0.8643170926517572\tAverage Loss: 0.1596833079082718\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8882166666666667\tAverage Loss: 0.15729335050678078\n",
      "\tTest: Average Accuracy: 0.8671126198083067\tAverage Loss: 0.15940375519261682\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.88935\tAverage Loss: 0.15718001717344746\n",
      "\tTest: Average Accuracy: 0.8666134185303515\tAverage Loss: 0.15945367532041235\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8902333333333333\tAverage Loss: 0.15709168384011413\n",
      "\tTest: Average Accuracy: 0.8672124600638977\tAverage Loss: 0.15939377116705772\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8911\tAverage Loss: 0.15700501717344748\n",
      "\tTest: Average Accuracy: 0.8679113418530351\tAverage Loss: 0.15932388298814398\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8923333333333333\tAverage Loss: 0.15688168384011414\n",
      "\tTest: Average Accuracy: 0.8684105431309904\tAverage Loss: 0.15927396286034845\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.89335\tAverage Loss: 0.15678001717344747\n",
      "\tTest: Average Accuracy: 0.8710063897763578\tAverage Loss: 0.1590143781958117\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8941166666666667\tAverage Loss: 0.1567033505067808\n",
      "\tTest: Average Accuracy: 0.8718051118210862\tAverage Loss: 0.15893450599133888\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8949666666666667\tAverage Loss: 0.1566183505067808\n",
      "\tTest: Average Accuracy: 0.8704073482428115\tAverage Loss: 0.15907428234916635\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8957166666666667\tAverage Loss: 0.15654335050678078\n",
      "\tTest: Average Accuracy: 0.873202875399361\tAverage Loss: 0.15879472963351138\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8962833333333333\tAverage Loss: 0.15648668384011413\n",
      "\tTest: Average Accuracy: 0.8734025559105432\tAverage Loss: 0.15877476158239318\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8971333333333333\tAverage Loss: 0.15640168384011413\n",
      "\tTest: Average Accuracy: 0.8734025559105432\tAverage Loss: 0.15877476158239318\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 32)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 32)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.31908333333333333\tAverage Loss: 0.21420668384011413\n",
      "\tTest: Average Accuracy: 0.5842651757188498\tAverage Loss: 0.1876884996015625\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.6548666666666667\tAverage Loss: 0.1806283505067808\n",
      "\tTest: Average Accuracy: 0.7009784345047924\tAverage Loss: 0.17601717372296827\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.7307\tAverage Loss: 0.17304501717344747\n",
      "\tTest: Average Accuracy: 0.7431110223642172\tAverage Loss: 0.17180391493702576\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.7775833333333333\tAverage Loss: 0.16835668384011412\n",
      "\tTest: Average Accuracy: 0.7836461661341853\tAverage Loss: 0.16775040056002896\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8092833333333334\tAverage Loss: 0.16518668384011412\n",
      "\tTest: Average Accuracy: 0.8071086261980831\tAverage Loss: 0.1654041545536392\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8250333333333333\tAverage Loss: 0.16361168384011412\n",
      "\tTest: Average Accuracy: 0.8187899361022364\tAverage Loss: 0.16423602356322384\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8342333333333334\tAverage Loss: 0.16269168384011412\n",
      "\tTest: Average Accuracy: 0.825379392971246\tAverage Loss: 0.1635770778763229\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.84045\tAverage Loss: 0.16207001717344746\n",
      "\tTest: Average Accuracy: 0.8310702875399361\tAverage Loss: 0.16300798841945388\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8455\tAverage Loss: 0.16156501717344746\n",
      "\tTest: Average Accuracy: 0.8348642172523961\tAverage Loss: 0.16262859544820787\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.84925\tAverage Loss: 0.16119001717344747\n",
      "\tTest: Average Accuracy: 0.838158945686901\tAverage Loss: 0.1622991226047574\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.85245\tAverage Loss: 0.16087001717344745\n",
      "\tTest: Average Accuracy: 0.8410543130990416\tAverage Loss: 0.16200958586354333\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8554166666666667\tAverage Loss: 0.1605733505067808\n",
      "\tTest: Average Accuracy: 0.8440495207667732\tAverage Loss: 0.1617100650967702\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8576666666666667\tAverage Loss: 0.16034835050678078\n",
      "\tTest: Average Accuracy: 0.8451477635782748\tAverage Loss: 0.16160024081562002\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8598\tAverage Loss: 0.16013501717344747\n",
      "\tTest: Average Accuracy: 0.8470447284345048\tAverage Loss: 0.16141054432999702\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8615666666666667\tAverage Loss: 0.15995835050678078\n",
      "\tTest: Average Accuracy: 0.8487420127795527\tAverage Loss: 0.16124081589549222\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8632333333333333\tAverage Loss: 0.15979168384011413\n",
      "\tTest: Average Accuracy: 0.8502396166134185\tAverage Loss: 0.16109105551210565\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.86455\tAverage Loss: 0.15966001717344747\n",
      "\tTest: Average Accuracy: 0.851138178913738\tAverage Loss: 0.16100119928207368\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8659333333333333\tAverage Loss: 0.15952168384011414\n",
      "\tTest: Average Accuracy: 0.8516373801916933\tAverage Loss: 0.16095127915427818\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8674833333333334\tAverage Loss: 0.15936668384011413\n",
      "\tTest: Average Accuracy: 0.852935303514377\tAverage Loss: 0.16082148682200978\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8688833333333333\tAverage Loss: 0.15922668384011412\n",
      "\tTest: Average Accuracy: 0.8536341853035144\tAverage Loss: 0.16075159864309604\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8698333333333333\tAverage Loss: 0.15913168384011414\n",
      "\tTest: Average Accuracy: 0.8547324281150159\tAverage Loss: 0.1606417743619459\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8711666666666666\tAverage Loss: 0.1589983505067808\n",
      "\tTest: Average Accuracy: 0.8560303514376997\tAverage Loss: 0.16051198202967754\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8721166666666667\tAverage Loss: 0.15890335050678078\n",
      "\tTest: Average Accuracy: 0.856629392971246\tAverage Loss: 0.1604520778763229\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.87295\tAverage Loss: 0.15882001717344746\n",
      "\tTest: Average Accuracy: 0.8576277955271565\tAverage Loss: 0.16035223762073184\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8737666666666667\tAverage Loss: 0.15873835050678078\n",
      "\tTest: Average Accuracy: 0.8582268370607029\tAverage Loss: 0.1602923334673772\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8748\tAverage Loss: 0.15863501717344747\n",
      "\tTest: Average Accuracy: 0.8595247603833865\tAverage Loss: 0.16016254113510883\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8757666666666667\tAverage Loss: 0.1585383505067808\n",
      "\tTest: Average Accuracy: 0.8598242811501597\tAverage Loss: 0.16013258905843153\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.87665\tAverage Loss: 0.15845001717344745\n",
      "\tTest: Average Accuracy: 0.860223642172524\tAverage Loss: 0.1600926529561951\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.87755\tAverage Loss: 0.15836001717344747\n",
      "\tTest: Average Accuracy: 0.8605231629392971\tAverage Loss: 0.1600627008795178\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8783833333333333\tAverage Loss: 0.15827668384011412\n",
      "\tTest: Average Accuracy: 0.8617212460063898\tAverage Loss: 0.15994289257280853\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 32)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 32)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 4:</h4> \n",
    "<p>Pass the entire dataset into the Neural Network at once is a little impossible when the data is too large.  So, to overcome this problem we need to divide the data into smaller sizes named Batch.<br>Batch size is one of the most important hyperparameters to tune in modern deep learning systems. Using a larger batch size to train the model as it allows computational speedups from the parallelism of GPUs, will lead to poor generalization. On the one extreme, using a batch equal to the entire dataset guarantees convergence to the global optima of the objective function. However, this is at the cost of slower, empirical convergence to that optima. On the other hand, using smaller batch sizes have been empirically shown to have faster convergence. But the downside of using a smaller batch size is that the model is not guaranteed to converge to the global optima.<br>\n",
    " The Neural Networks with batch size 16 and 128 are shown below. </p>\n",
    " <p>From now on, the batch size is 16.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.59205\tAverage Loss: 0.18691001717344746\n",
      "\tTest: Average Accuracy: 0.772\tAverage Loss: 0.16891501717344748\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8100333333333334\tAverage Loss: 0.16511168384011413\n",
      "\tTest: Average Accuracy: 0.8138\tAverage Loss: 0.1647350171734475\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8356666666666667\tAverage Loss: 0.1625483505067808\n",
      "\tTest: Average Accuracy: 0.8301\tAverage Loss: 0.1631050171734475\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8462333333333333\tAverage Loss: 0.16149168384011414\n",
      "\tTest: Average Accuracy: 0.8382\tAverage Loss: 0.1622950171734475\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.85285\tAverage Loss: 0.16083001717344747\n",
      "\tTest: Average Accuracy: 0.8425\tAverage Loss: 0.16186501717344748\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8576166666666667\tAverage Loss: 0.1603533505067808\n",
      "\tTest: Average Accuracy: 0.8447\tAverage Loss: 0.16164501717344748\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8606333333333334\tAverage Loss: 0.16005168384011412\n",
      "\tTest: Average Accuracy: 0.85\tAverage Loss: 0.16111501717344748\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8645666666666667\tAverage Loss: 0.1596583505067808\n",
      "\tTest: Average Accuracy: 0.8507\tAverage Loss: 0.1610450171734475\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8672833333333333\tAverage Loss: 0.15938668384011412\n",
      "\tTest: Average Accuracy: 0.8503\tAverage Loss: 0.16108501717344748\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8693166666666666\tAverage Loss: 0.15918335050678079\n",
      "\tTest: Average Accuracy: 0.8534\tAverage Loss: 0.1607750171734475\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8710166666666667\tAverage Loss: 0.15901335050678078\n",
      "\tTest: Average Accuracy: 0.8559\tAverage Loss: 0.1605250171734475\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8733666666666666\tAverage Loss: 0.1587783505067808\n",
      "\tTest: Average Accuracy: 0.8568\tAverage Loss: 0.1604350171734475\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.87455\tAverage Loss: 0.15866001717344747\n",
      "\tTest: Average Accuracy: 0.8578\tAverage Loss: 0.16033501717344747\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8764166666666666\tAverage Loss: 0.1584733505067808\n",
      "\tTest: Average Accuracy: 0.8583\tAverage Loss: 0.16028501717344748\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8782833333333333\tAverage Loss: 0.15828668384011413\n",
      "\tTest: Average Accuracy: 0.8596\tAverage Loss: 0.1601550171734475\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.87985\tAverage Loss: 0.15813001717344746\n",
      "\tTest: Average Accuracy: 0.8618\tAverage Loss: 0.1599350171734475\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8808833333333334\tAverage Loss: 0.15802668384011412\n",
      "\tTest: Average Accuracy: 0.8626\tAverage Loss: 0.1598550171734475\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.88315\tAverage Loss: 0.15780001717344747\n",
      "\tTest: Average Accuracy: 0.8639\tAverage Loss: 0.15972501717344748\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8843\tAverage Loss: 0.15768501717344746\n",
      "\tTest: Average Accuracy: 0.8638\tAverage Loss: 0.15973501717344749\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8855833333333333\tAverage Loss: 0.15755668384011412\n",
      "\tTest: Average Accuracy: 0.8644\tAverage Loss: 0.15967501717344748\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8865333333333333\tAverage Loss: 0.15746168384011414\n",
      "\tTest: Average Accuracy: 0.8663\tAverage Loss: 0.15948501717344749\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8871666666666667\tAverage Loss: 0.1573983505067808\n",
      "\tTest: Average Accuracy: 0.8661\tAverage Loss: 0.15950501717344748\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8886666666666667\tAverage Loss: 0.1572483505067808\n",
      "\tTest: Average Accuracy: 0.8663\tAverage Loss: 0.15948501717344749\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8896666666666667\tAverage Loss: 0.1571483505067808\n",
      "\tTest: Average Accuracy: 0.8654\tAverage Loss: 0.1595750171734475\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.89105\tAverage Loss: 0.15701001717344745\n",
      "\tTest: Average Accuracy: 0.8658\tAverage Loss: 0.15953501717344748\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8921666666666667\tAverage Loss: 0.1568983505067808\n",
      "\tTest: Average Accuracy: 0.8651\tAverage Loss: 0.1596050171734475\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8924166666666666\tAverage Loss: 0.1568733505067808\n",
      "\tTest: Average Accuracy: 0.8661\tAverage Loss: 0.15950501717344748\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8941\tAverage Loss: 0.15670501717344745\n",
      "\tTest: Average Accuracy: 0.8666\tAverage Loss: 0.15945501717344748\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.89465\tAverage Loss: 0.15665001717344745\n",
      "\tTest: Average Accuracy: 0.8667\tAverage Loss: 0.15944501717344747\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8954833333333333\tAverage Loss: 0.15656668384011413\n",
      "\tTest: Average Accuracy: 0.8672\tAverage Loss: 0.15939501717344748\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 16)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 16)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.5723947228144989\tAverage Loss: 0.18887554489199757\n",
      "\tTest: Average Accuracy: 0.765625\tAverage Loss: 0.16955251717344746\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.7983630952380952\tAverage Loss: 0.16627870764963795\n",
      "\tTest: Average Accuracy: 0.8201147151898734\tAverage Loss: 0.16410354565446011\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8302683013503909\tAverage Loss: 0.16308818703840838\n",
      "\tTest: Average Accuracy: 0.8314873417721519\tAverage Loss: 0.16296628299623228\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.8424673507462687\tAverage Loss: 0.1618682820988206\n",
      "\tTest: Average Accuracy: 0.8407832278481012\tAverage Loss: 0.16203669438863733\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8499189321250888\tAverage Loss: 0.16112312396093859\n",
      "\tTest: Average Accuracy: 0.8446400316455697\tAverage Loss: 0.1616510140088905\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.855527052238806\tAverage Loss: 0.16056231194956685\n",
      "\tTest: Average Accuracy: 0.849189082278481\tAverage Loss: 0.16119610894559935\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8599413646055437\tAverage Loss: 0.1601208807128931\n",
      "\tTest: Average Accuracy: 0.8530458860759493\tAverage Loss: 0.16081042856585254\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8639947583511016\tAverage Loss: 0.15971554133833732\n",
      "\tTest: Average Accuracy: 0.854628164556962\tAverage Loss: 0.16065220071775127\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8674762348969439\tAverage Loss: 0.15936739368375308\n",
      "\tTest: Average Accuracy: 0.8573971518987342\tAverage Loss: 0.16037530198357405\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8700026652452025\tAverage Loss: 0.15911475064892722\n",
      "\tTest: Average Accuracy: 0.860067246835443\tAverage Loss: 0.16010829248990316\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8726345948827292\tAverage Loss: 0.15885155768517453\n",
      "\tTest: Average Accuracy: 0.8607594936708861\tAverage Loss: 0.16003906780635885\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.874883395522388\tAverage Loss: 0.15862667762120866\n",
      "\tTest: Average Accuracy: 0.8630340189873418\tAverage Loss: 0.15981161527471327\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8766657782515992\tAverage Loss: 0.15844843934828756\n",
      "\tTest: Average Accuracy: 0.8643196202531646\tAverage Loss: 0.159683055148131\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8783981876332623\tAverage Loss: 0.15827519841012125\n",
      "\tTest: Average Accuracy: 0.8652096518987342\tAverage Loss: 0.15959405198357404\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8803693585643213\tAverage Loss: 0.15807808131701534\n",
      "\tTest: Average Accuracy: 0.8668908227848101\tAverage Loss: 0.15942593489496645\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8819185323383085\tAverage Loss: 0.15792316393961664\n",
      "\tTest: Average Accuracy: 0.8692642405063291\tAverage Loss: 0.15918859312281455\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8834677061122957\tAverage Loss: 0.1577682465622179\n",
      "\tTest: Average Accuracy: 0.8693631329113924\tAverage Loss: 0.15917870388230823\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.8850113272921108\tAverage Loss: 0.15761388444423638\n",
      "\tTest: Average Accuracy: 0.8710443037974683\tAverage Loss: 0.15901058679370061\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.8861662668798863\tAverage Loss: 0.15749839048545886\n",
      "\tTest: Average Accuracy: 0.8725276898734177\tAverage Loss: 0.1588622481861057\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.8874100479744137\tAverage Loss: 0.1573740123760061\n",
      "\tTest: Average Accuracy: 0.8722310126582279\tAverage Loss: 0.15889191590762466\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8888259594882729\tAverage Loss: 0.15723242122462017\n",
      "\tTest: Average Accuracy: 0.8716376582278481\tAverage Loss: 0.15895125135066265\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8899309257285004\tAverage Loss: 0.15712192460059743\n",
      "\tTest: Average Accuracy: 0.8725276898734177\tAverage Loss: 0.1588622481861057\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.890647210376688\tAverage Loss: 0.15705029613577867\n",
      "\tTest: Average Accuracy: 0.8716376582278481\tAverage Loss: 0.15895125135066265\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8916633351101635\tAverage Loss: 0.15694868366243112\n",
      "\tTest: Average Accuracy: 0.8715387658227848\tAverage Loss: 0.15896114059116898\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8931958511016347\tAverage Loss: 0.156795432063284\n",
      "\tTest: Average Accuracy: 0.8721321202531646\tAverage Loss: 0.15890180514813101\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8940120824449183\tAverage Loss: 0.15671380892895564\n",
      "\tTest: Average Accuracy: 0.8721321202531646\tAverage Loss: 0.15890180514813101\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8950282071783938\tAverage Loss: 0.1566121964556081\n",
      "\tTest: Average Accuracy: 0.8727254746835443\tAverage Loss: 0.15884246970509303\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.8956612029140014\tAverage Loss: 0.15654889688204732\n",
      "\tTest: Average Accuracy: 0.8724287974683544\tAverage Loss: 0.15887213742661202\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8960943052594172\tAverage Loss: 0.15650558664750575\n",
      "\tTest: Average Accuracy: 0.872626582278481\tAverage Loss: 0.15885235894559935\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.8974269278606966\tAverage Loss: 0.15637232438737783\n",
      "\tTest: Average Accuracy: 0.8730221518987342\tAverage Loss: 0.15881280198357403\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 128)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 128)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 5:</h4> \n",
    "<p>We are using a limited dataset and to optimise the learning and the graph we are using Gradient Descent which is an iterative process. So, updating the weights with single pass or one epoch is not enough. As the number of epochs increases, more number of times the weight are changed in the neural network and the curve goes from underfitting to optimal to overfitting curve. Here is a neural network with 40 epochs. The aim is to see the overfitting curve.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.6062\tAverage Loss: 0.18549501717344746\n",
      "\tTest: Average Accuracy: 0.7797\tAverage Loss: 0.1681450171734475\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.8108166666666666\tAverage Loss: 0.1650333505067808\n",
      "\tTest: Average Accuracy: 0.8127\tAverage Loss: 0.1648450171734475\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.8346166666666667\tAverage Loss: 0.16265335050678079\n",
      "\tTest: Average Accuracy: 0.8252\tAverage Loss: 0.1635950171734475\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.84515\tAverage Loss: 0.16160001717344746\n",
      "\tTest: Average Accuracy: 0.8355\tAverage Loss: 0.16256501717344748\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.8517333333333333\tAverage Loss: 0.16094168384011412\n",
      "\tTest: Average Accuracy: 0.8396\tAverage Loss: 0.1621550171734475\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.8565666666666667\tAverage Loss: 0.16045835050678078\n",
      "\tTest: Average Accuracy: 0.845\tAverage Loss: 0.16161501717344748\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.8608166666666667\tAverage Loss: 0.1600333505067808\n",
      "\tTest: Average Accuracy: 0.848\tAverage Loss: 0.16131501717344748\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.8642666666666666\tAverage Loss: 0.1596883505067808\n",
      "\tTest: Average Accuracy: 0.8511\tAverage Loss: 0.16100501717344748\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 0.8671666666666666\tAverage Loss: 0.1593983505067808\n",
      "\tTest: Average Accuracy: 0.853\tAverage Loss: 0.16081501717344748\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 0.8699666666666667\tAverage Loss: 0.1591183505067808\n",
      "\tTest: Average Accuracy: 0.8544\tAverage Loss: 0.16067501717344748\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 0.8720333333333333\tAverage Loss: 0.15891168384011412\n",
      "\tTest: Average Accuracy: 0.8582\tAverage Loss: 0.1602950171734475\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 0.8742\tAverage Loss: 0.15869501717344747\n",
      "\tTest: Average Accuracy: 0.8607\tAverage Loss: 0.1600450171734475\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 0.8764666666666666\tAverage Loss: 0.1584683505067808\n",
      "\tTest: Average Accuracy: 0.8607\tAverage Loss: 0.1600450171734475\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 0.8781166666666667\tAverage Loss: 0.1583033505067808\n",
      "\tTest: Average Accuracy: 0.8599\tAverage Loss: 0.1601250171734475\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 0.8795166666666666\tAverage Loss: 0.1581633505067808\n",
      "\tTest: Average Accuracy: 0.8616\tAverage Loss: 0.15995501717344748\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 0.8812333333333333\tAverage Loss: 0.15799168384011414\n",
      "\tTest: Average Accuracy: 0.8621\tAverage Loss: 0.1599050171734475\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 0.8827166666666667\tAverage Loss: 0.1578433505067808\n",
      "\tTest: Average Accuracy: 0.8634\tAverage Loss: 0.1597750171734475\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 0.88405\tAverage Loss: 0.15771001717344746\n",
      "\tTest: Average Accuracy: 0.864\tAverage Loss: 0.1597150171734475\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 0.88515\tAverage Loss: 0.15760001717344746\n",
      "\tTest: Average Accuracy: 0.8641\tAverage Loss: 0.15970501717344748\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 0.88595\tAverage Loss: 0.15752001717344746\n",
      "\tTest: Average Accuracy: 0.8648\tAverage Loss: 0.1596350171734475\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 0.8873333333333333\tAverage Loss: 0.15738168384011414\n",
      "\tTest: Average Accuracy: 0.8641\tAverage Loss: 0.15970501717344748\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 0.8886166666666667\tAverage Loss: 0.1572533505067808\n",
      "\tTest: Average Accuracy: 0.8666\tAverage Loss: 0.15945501717344748\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 0.8896166666666666\tAverage Loss: 0.1571533505067808\n",
      "\tTest: Average Accuracy: 0.8659\tAverage Loss: 0.1595250171734475\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 0.8910166666666667\tAverage Loss: 0.1570133505067808\n",
      "\tTest: Average Accuracy: 0.8664\tAverage Loss: 0.15947501717344748\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 0.8919833333333334\tAverage Loss: 0.15691668384011412\n",
      "\tTest: Average Accuracy: 0.8674\tAverage Loss: 0.1593750171734475\n",
      "Epoch 26:\n",
      "\tTrain: Average Accuracy: 0.8930333333333333\tAverage Loss: 0.15681168384011412\n",
      "\tTest: Average Accuracy: 0.8673\tAverage Loss: 0.1593850171734475\n",
      "Epoch 27:\n",
      "\tTrain: Average Accuracy: 0.8944666666666666\tAverage Loss: 0.1566683505067808\n",
      "\tTest: Average Accuracy: 0.8678\tAverage Loss: 0.15933501717344747\n",
      "Epoch 28:\n",
      "\tTrain: Average Accuracy: 0.89505\tAverage Loss: 0.15661001717344747\n",
      "\tTest: Average Accuracy: 0.8681\tAverage Loss: 0.1593050171734475\n",
      "Epoch 29:\n",
      "\tTrain: Average Accuracy: 0.8959166666666667\tAverage Loss: 0.1565233505067808\n",
      "\tTest: Average Accuracy: 0.8689\tAverage Loss: 0.15922501717344748\n",
      "Epoch 30:\n",
      "\tTrain: Average Accuracy: 0.89715\tAverage Loss: 0.15640001717344745\n",
      "\tTest: Average Accuracy: 0.8697\tAverage Loss: 0.15914501717344748\n",
      "Epoch 31:\n",
      "\tTrain: Average Accuracy: 0.8976166666666666\tAverage Loss: 0.15635335050678079\n",
      "\tTest: Average Accuracy: 0.8696\tAverage Loss: 0.1591550171734475\n",
      "Epoch 32:\n",
      "\tTrain: Average Accuracy: 0.89885\tAverage Loss: 0.15623001717344745\n",
      "\tTest: Average Accuracy: 0.8697\tAverage Loss: 0.15914501717344748\n",
      "Epoch 33:\n",
      "\tTrain: Average Accuracy: 0.8992166666666667\tAverage Loss: 0.1561933505067808\n",
      "\tTest: Average Accuracy: 0.8701\tAverage Loss: 0.1591050171734475\n",
      "Epoch 34:\n",
      "\tTrain: Average Accuracy: 0.9000166666666667\tAverage Loss: 0.1561133505067808\n",
      "\tTest: Average Accuracy: 0.8706\tAverage Loss: 0.1590550171734475\n",
      "Epoch 35:\n",
      "\tTrain: Average Accuracy: 0.9009166666666667\tAverage Loss: 0.1560233505067808\n",
      "\tTest: Average Accuracy: 0.8705\tAverage Loss: 0.15906501717344748\n",
      "Epoch 36:\n",
      "\tTrain: Average Accuracy: 0.90175\tAverage Loss: 0.15594001717344746\n",
      "\tTest: Average Accuracy: 0.8706\tAverage Loss: 0.1590550171734475\n",
      "Epoch 37:\n",
      "\tTrain: Average Accuracy: 0.9025\tAverage Loss: 0.15586501717344747\n",
      "\tTest: Average Accuracy: 0.8716\tAverage Loss: 0.15895501717344748\n",
      "Epoch 38:\n",
      "\tTrain: Average Accuracy: 0.90315\tAverage Loss: 0.15580001717344746\n",
      "\tTest: Average Accuracy: 0.8708\tAverage Loss: 0.15903501717344748\n",
      "Epoch 39:\n",
      "\tTrain: Average Accuracy: 0.9037833333333334\tAverage Loss: 0.15573668384011413\n",
      "\tTest: Average Accuracy: 0.8702\tAverage Loss: 0.15909501717344748\n",
      "Epoch 40:\n",
      "\tTrain: Average Accuracy: 0.9043\tAverage Loss: 0.15568501717344746\n",
      "\tTest: Average Accuracy: 0.8709\tAverage Loss: 0.1590250171734475\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 40\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 16)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 16)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(30, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(EPOCHS))\n",
    "plt.plot(x, log['train_accuracy'], color=\"purple\")\n",
    "plt.plot(x, log['test_accuracy'], color=\"blue\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(EPOCHS))\n",
    "plt.plot(x, log['train_loss'], color=\"purple\")\n",
    "plt.plot(x, log['test_loss'], color=\"blue\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualizing Data Reduced to two Dimensions</h3>\n",
    "<p> The goal of this section is to reduce the demensions of the input to two and plot the chart of it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 0.2346\tAverage Loss: 0.22265501717344746\n",
      "\tTest: Average Accuracy: 0.3191\tAverage Loss: 0.21420501717344748\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 0.35413333333333336\tAverage Loss: 0.21070168384011412\n",
      "\tTest: Average Accuracy: 0.3823\tAverage Loss: 0.20788501717344748\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 0.4040666666666667\tAverage Loss: 0.2057083505067808\n",
      "\tTest: Average Accuracy: 0.4701\tAverage Loss: 0.19910501717344747\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 0.6028666666666667\tAverage Loss: 0.1858283505067808\n",
      "\tTest: Average Accuracy: 0.6979\tAverage Loss: 0.17632501717344748\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 0.723\tAverage Loss: 0.17381501717344747\n",
      "\tTest: Average Accuracy: 0.7272\tAverage Loss: 0.1733950171734475\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 0.7505833333333334\tAverage Loss: 0.17105668384011413\n",
      "\tTest: Average Accuracy: 0.7587\tAverage Loss: 0.17024501717344748\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 0.7695\tAverage Loss: 0.16916501717344745\n",
      "\tTest: Average Accuracy: 0.7787\tAverage Loss: 0.16824501717344748\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 0.7877166666666666\tAverage Loss: 0.16734335050678079\n",
      "\tTest: Average Accuracy: 0.7919\tAverage Loss: 0.1669250171734475\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 8\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10, 16)\n",
    "TESTLOADER = Dataloader(test, testL, 10, 16)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(784, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "#network.add_layer(100, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(2, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform', low = 0.0001, high = 0.001)\n",
    "network.add_layer(10, activation=Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "train = trainData.copy()\n",
    "trainL = trainLabels.copy()\n",
    "test = testData.copy()\n",
    "testL = testLabels.copy()\n",
    "\n",
    "TRAINLOADER = Dataloader(train, trainL, 10)\n",
    "TESTLOADER = Dataloader(test, testL, 10)\n",
    "\n",
    "trainOut2D = network.output2D(TRAINLOADER)\n",
    "testOut2D = network.output2D(TESTLOADER)\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame({'trainOut2D_x': trainOut2D[:,0].tolist(),'trainOut2D_y':trainOut2D[:,1].tolist() ,'Labels':trainL.flatten().tolist()[0]})\n",
    "test_df = pd.DataFrame({'testOut2D_x': testOut2D[:,0].tolist(),'testOut2D_y':testOut2D[:,1].tolist() ,'Labels':testL.flatten().tolist()[0]})\n",
    "\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, N_CLASSES))\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(N_CLASSES):\n",
    "    x = train_df[train_df['Labels'] == i]['trainOut2D_x']\n",
    "    y = train_df[train_df['Labels'] == i]['trainOut2D_y']\n",
    "    plt.scatter(x, y, c = colors[i].reshape(1,-1), label=str(i))\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(N_CLASSES):\n",
    "    x = test_df[test_df['Labels'] == i]['testOut2D_x']\n",
    "    y = test_df[test_df['Labels'] == i]['testOut2D_y']\n",
    "    plt.scatter(x, y, c = colors[i].reshape(1,-1),label=str(i))\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
